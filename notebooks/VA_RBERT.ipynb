{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9a23f647fdfe42b1b69b75ccf135d496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30c9bd9df80545f29ee728e23d437982",
              "IPY_MODEL_3bc03b231d534700ba5f535edfb29890",
              "IPY_MODEL_7669cf40a1834d4a8dcc0477b9c2281a"
            ],
            "layout": "IPY_MODEL_358c8fe913ba4b98ab9d9d798db11dd6"
          }
        },
        "30c9bd9df80545f29ee728e23d437982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04db0ed1aa524ef78477416a3d8af233",
            "placeholder": "​",
            "style": "IPY_MODEL_13aad6fb8d7940dca1156c758d1c7ec9",
            "value": "Downloading vocab.txt: 100%"
          }
        },
        "3bc03b231d534700ba5f535edfb29890": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e07c67493d6943adae2dacd276b1f97a",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8180075aae54696aa8d27070fdcfa22",
            "value": 231508
          }
        },
        "7669cf40a1834d4a8dcc0477b9c2281a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acf2fee5a4714287b5b91fb4c7c43fae",
            "placeholder": "​",
            "style": "IPY_MODEL_57ec4691af7f455795a10483f16889ea",
            "value": " 226k/226k [00:00&lt;00:00, 1.96MB/s]"
          }
        },
        "358c8fe913ba4b98ab9d9d798db11dd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04db0ed1aa524ef78477416a3d8af233": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13aad6fb8d7940dca1156c758d1c7ec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e07c67493d6943adae2dacd276b1f97a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8180075aae54696aa8d27070fdcfa22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "acf2fee5a4714287b5b91fb4c7c43fae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57ec4691af7f455795a10483f16889ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0211191ff6264a648974b156a13a13d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b79b856e8d04204ad652626b19244c4",
              "IPY_MODEL_91ab95751ded41e4a2c7e0342a23a522",
              "IPY_MODEL_cb2763472ca24cd7a26c842f1c6a3ee6"
            ],
            "layout": "IPY_MODEL_fba3d9f7672b479d99140c7dbb75e282"
          }
        },
        "5b79b856e8d04204ad652626b19244c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cd51da893754a9e81b29652f2361244",
            "placeholder": "​",
            "style": "IPY_MODEL_5b1325074cdb4f23b8f126e0738d8114",
            "value": "Downloading tokenizer_config.json: 100%"
          }
        },
        "91ab95751ded41e4a2c7e0342a23a522": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1ec281487e44189bfa53c5082791e9e",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17a933360f9b4487b3c2273770003e8b",
            "value": 28
          }
        },
        "cb2763472ca24cd7a26c842f1c6a3ee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb3c6269d7d848a4a2978e10c138c50b",
            "placeholder": "​",
            "style": "IPY_MODEL_44d5469803f34333b92a0b17016b2f0c",
            "value": " 28.0/28.0 [00:00&lt;00:00, 490B/s]"
          }
        },
        "fba3d9f7672b479d99140c7dbb75e282": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cd51da893754a9e81b29652f2361244": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b1325074cdb4f23b8f126e0738d8114": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1ec281487e44189bfa53c5082791e9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17a933360f9b4487b3c2273770003e8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb3c6269d7d848a4a2978e10c138c50b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44d5469803f34333b92a0b17016b2f0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99edd59928a64728a0829fe978dbb1a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8ed7a3b46fc40379b1515bf92e0ad55",
              "IPY_MODEL_6b819b52940d4fa2a4620c1269ae5493",
              "IPY_MODEL_4430dc42a1e64a2c904359ac144068a4"
            ],
            "layout": "IPY_MODEL_047d71c573e744c4935728b10d455810"
          }
        },
        "f8ed7a3b46fc40379b1515bf92e0ad55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab68b6be2e6f4800bbdfd697c76e487b",
            "placeholder": "​",
            "style": "IPY_MODEL_8156bda7ea2b4178869d2522aa2f1d53",
            "value": "Downloading config.json: 100%"
          }
        },
        "6b819b52940d4fa2a4620c1269ae5493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7d777472c8743edb0edccde93aee6be",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40e62b1a947a4c8e8e3013320b9b96f4",
            "value": 570
          }
        },
        "4430dc42a1e64a2c904359ac144068a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b5cfbd5c0074076adf1eb36485b6c83",
            "placeholder": "​",
            "style": "IPY_MODEL_28b5efe60ebb46c38e3d27c7ad5dbabd",
            "value": " 570/570 [00:00&lt;00:00, 15.7kB/s]"
          }
        },
        "047d71c573e744c4935728b10d455810": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab68b6be2e6f4800bbdfd697c76e487b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8156bda7ea2b4178869d2522aa2f1d53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7d777472c8743edb0edccde93aee6be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40e62b1a947a4c8e8e3013320b9b96f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b5cfbd5c0074076adf1eb36485b6c83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28b5efe60ebb46c38e3d27c7ad5dbabd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b28bf304eb16457d994cd7b08c4ca982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5db166ca820a41899b519a79cf901813",
              "IPY_MODEL_3a86a23d52354d82817e422141f1a208",
              "IPY_MODEL_272af323603843299d0ecfe31c3ab647"
            ],
            "layout": "IPY_MODEL_e1b0a14bacb948e38e8b9375165a1ae0"
          }
        },
        "5db166ca820a41899b519a79cf901813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30a5c1ae163d4124be7136115b972052",
            "placeholder": "​",
            "style": "IPY_MODEL_27ed2605b6ec4d6c8ec1ef31355d3b78",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "3a86a23d52354d82817e422141f1a208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27363542439a4339b4b630063f25b783",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f67ae90202ec4b239ee9a08e3dd114f4",
            "value": 440473133
          }
        },
        "272af323603843299d0ecfe31c3ab647": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6554a2f667974b19b2301c3ff988eeac",
            "placeholder": "​",
            "style": "IPY_MODEL_0b6b5fa5db164bb8b4155aa6c3c3f724",
            "value": " 420M/420M [00:18&lt;00:00, 28.9MB/s]"
          }
        },
        "e1b0a14bacb948e38e8b9375165a1ae0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30a5c1ae163d4124be7136115b972052": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27ed2605b6ec4d6c8ec1ef31355d3b78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27363542439a4339b4b630063f25b783": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f67ae90202ec4b239ee9a08e3dd114f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6554a2f667974b19b2301c3ff988eeac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b6b5fa5db164bb8b4155aa6c3c3f724": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weBEWAcEoJJd"
      },
      "source": [
        "# Entity Relation Extraction using R-BERT\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFV0nYifAVSp",
        "outputId": "b7cda589-c7f2-4f22-f5a1-a6a5c66f77a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Connect to google drive (where the data is, to access it):\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xW2lQw7Ueodx"
      },
      "source": [
        "# 1. Install dependencies, import modules and load helper functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wl6msvLX_kDS",
        "outputId": "f6d096f2-d3ca-4f67-a7b9-f69796fda5bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! pip install transformers #"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.3-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 10.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 897 kB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.21.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcFPYsPF_kWM"
      },
      "source": [
        "# Classes for storing individual sentences:\n",
        "\n",
        "class InputExample(object):\n",
        "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
        "\n",
        "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
        "        \"\"\"Constructs a InputExample.\n",
        "\n",
        "        Args:\n",
        "            guid: Unique id for the example.\n",
        "            text_a: string. The untokenized text of the first sequence. For single\n",
        "            sequence tasks, only this sequence must be specified.\n",
        "            text_b: (Optional) string. The untokenized text of the second sequence.\n",
        "            Only must be specified for sequence pair tasks.\n",
        "            label: (Optional) string. The label of the example. This should be\n",
        "            specified for train and dev examples, but not for test examples.\n",
        "        \"\"\"\n",
        "        self.guid = guid\n",
        "        self.text_a = text_a\n",
        "        self.text_b = text_b\n",
        "        self.label = label\n",
        "\n",
        "class InputFeatures(object):\n",
        "    \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 input_ids,\n",
        "                 input_mask,\n",
        "                 e11_p, e12_p, e21_p, e22_p,\n",
        "                 e1_mask, e2_mask,\n",
        "                 segment_ids,\n",
        "                 label_id):\n",
        "        self.input_ids = input_ids\n",
        "        self.input_mask = input_mask\n",
        "        self.segment_ids = segment_ids\n",
        "        self.label_id = label_id\n",
        "\n",
        "        #add enitity position and entity mask for BERT\n",
        "        self.e11_p = e11_p\n",
        "        self.e12_p = e12_p\n",
        "        self.e21_p = e21_p\n",
        "        self.e22_p = e22_p\n",
        "        self.e1_mask = e1_mask\n",
        "        self.e2_mask = e2_mask\n",
        "        \n",
        "    def print_contents(self):\n",
        "        print(self.input_ids,self.input_mask,self.segment_ids, self.label_id,\n",
        "        self.e11_p,self.e12_p,self.e21_p,\n",
        "        self.e22_p,self.e1_mask, self.e2_mask)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri0281T7AVD3"
      },
      "source": [
        "# Functions for reading in the data:\n",
        "\n",
        "import csv\n",
        "import sys \n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def read_tsv(input_file, quotechar=None):\n",
        "    \"\"\"Reads a tab separated value file.\"\"\"\n",
        "    with open(input_file, \"r\", encoding=\"utf-8-sig\") as f:\n",
        "        reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n",
        "        lines = []\n",
        "        for line in reader:\n",
        "            if sys.version_info[0] == 2:\n",
        "                line = list(cell for cell in line)\n",
        "            lines.append(line)\n",
        "        return lines\n",
        "      \n",
        "def create_examples(lines, set_type):\n",
        "    \"\"\"Creates examples for the training and test sets.\n",
        "  \n",
        "    $AZATHIOPRINE$ is an immunosuppressive drug that is used to treat #RHEUMATOID ARTHRITIS#\t8\ttreats2\ttreats1\t2\n",
        "    \n",
        "    $ denotes first entity, # denotes second entitiy, 8 denotes type of relation and 2 denotes direction\n",
        "    \"\"\"\n",
        "    examples = []\n",
        "    for (i, line) in enumerate(lines):\n",
        "\n",
        "        guid = \"%s-%s\" % (set_type, i)\n",
        "        logger.info(line)\n",
        "        text_a = line[1]\n",
        "        text_b = None\n",
        "        label = line[2]\n",
        "        # print(text_a)\n",
        "        examples.append(\n",
        "            InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
        "    return examples\n",
        "\n",
        "def get_train_examples(data_dir):\n",
        "    logger.info(\"LOOKING AT {}\".format(\n",
        "        os.path.join(data_dir, \"train.tsv\")))\n",
        "    return create_examples(\n",
        "        read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
        "    \n",
        "\n",
        "def get_test_examples(data_dir):\n",
        "    return create_examples(\n",
        "        read_tsv(os.path.join(data_dir, \"test.tsv\")), \"test\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzO2a_dkeod-"
      },
      "source": [
        "# 2. Read in the data and convert to features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHu_IJdsAtul",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "9a23f647fdfe42b1b69b75ccf135d496",
            "30c9bd9df80545f29ee728e23d437982",
            "3bc03b231d534700ba5f535edfb29890",
            "7669cf40a1834d4a8dcc0477b9c2281a",
            "358c8fe913ba4b98ab9d9d798db11dd6",
            "04db0ed1aa524ef78477416a3d8af233",
            "13aad6fb8d7940dca1156c758d1c7ec9",
            "e07c67493d6943adae2dacd276b1f97a",
            "c8180075aae54696aa8d27070fdcfa22",
            "acf2fee5a4714287b5b91fb4c7c43fae",
            "57ec4691af7f455795a10483f16889ea",
            "0211191ff6264a648974b156a13a13d7",
            "5b79b856e8d04204ad652626b19244c4",
            "91ab95751ded41e4a2c7e0342a23a522",
            "cb2763472ca24cd7a26c842f1c6a3ee6",
            "fba3d9f7672b479d99140c7dbb75e282",
            "9cd51da893754a9e81b29652f2361244",
            "5b1325074cdb4f23b8f126e0738d8114",
            "d1ec281487e44189bfa53c5082791e9e",
            "17a933360f9b4487b3c2273770003e8b",
            "cb3c6269d7d848a4a2978e10c138c50b",
            "44d5469803f34333b92a0b17016b2f0c",
            "99edd59928a64728a0829fe978dbb1a5",
            "f8ed7a3b46fc40379b1515bf92e0ad55",
            "6b819b52940d4fa2a4620c1269ae5493",
            "4430dc42a1e64a2c904359ac144068a4",
            "047d71c573e744c4935728b10d455810",
            "ab68b6be2e6f4800bbdfd697c76e487b",
            "8156bda7ea2b4178869d2522aa2f1d53",
            "d7d777472c8743edb0edccde93aee6be",
            "40e62b1a947a4c8e8e3013320b9b96f4",
            "5b5cfbd5c0074076adf1eb36485b6c83",
            "28b5efe60ebb46c38e3d27c7ad5dbabd"
          ]
        },
        "outputId": "e415b61c-12be-4b06-d75c-c93aa620d408"
      },
      "source": [
        "from transformers import WEIGHTS_NAME, BertConfig, BertTokenizer\n",
        "\n",
        "# Configuration parameters:\n",
        "use_entity_indicator=True\n",
        "max_seq_len=176\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "        'bert-base-uncased', do_lower_case=True)\n",
        "# bert-base-uncased\n",
        "n_labels = 18\n",
        "labels = [str(i) for i in range(n_labels)]\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a23f647fdfe42b1b69b75ccf135d496"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0211191ff6264a648974b156a13a13d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99edd59928a64728a0829fe978dbb1a5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2x4LEfqAz4c"
      },
      "source": [
        "# BERT Class for converting the input to features according to the required input form\n",
        "def convert_examples_to_features(examples, label_list, max_seq_len,\n",
        "                                 tokenizer,\n",
        "                                 cls_token='[CLS]',\n",
        "                                 cls_token_segment_id=1,\n",
        "                                 sep_token='[SEP]',\n",
        "                                 pad_token=0,\n",
        "                                 pad_token_segment_id=0,\n",
        "                                 sequence_a_segment_id=0,\n",
        "                                 sequence_b_segment_id=1,\n",
        "                                 mask_padding_with_zero=True):\n",
        " \n",
        "    ''' In: sentences with entities marked by $$ and ## around them\n",
        "      Out: sentence represented as object of the InputFeature class '''\n",
        "\n",
        "    label_map = {label: i for i, label in enumerate(label_list)}\n",
        "\n",
        "    features = []\n",
        "    for (ex_index, example) in enumerate(examples):\n",
        "        if ex_index % 10000 == 0:\n",
        "            logger.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n",
        "\n",
        "        tokens_a = tokenizer.tokenize(example.text_a)\n",
        "        \n",
        "        #convert the entity information to features as well\n",
        "        l = len(tokens_a)\n",
        "        # print(example.text_a)\n",
        "        # the start position of entity1:\n",
        "        e11_p = tokens_a.index(\"#\") + 1  \n",
        "        # the end position of entity1\n",
        "        e12_p = l - tokens_a[::-1].index(\"#\") + 1  \n",
        "        # the start position of entity2\n",
        "        e21_p = tokens_a.index(\"$\") + 1  \n",
        "        # the end position of entity2\n",
        "        e22_p = l - tokens_a[::-1].index(\"$\") + 1 \n",
        "\n",
        "        tokens_b = None\n",
        "\n",
        "        if example.text_b:\n",
        "            tokens_b = tokenizer.tokenize(example.text_b)\n",
        "            # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
        "            # length is less than the specified length.\n",
        "            # Account for [CLS], [SEP], [SEP] with \"- 3\".\n",
        "            special_tokens_count = 3\n",
        "            _truncate_seq_pair(tokens_a, tokens_b,\n",
        "                               max_seq_len - special_tokens_count)\n",
        "        else:\n",
        "            # Account for [CLS] and [SEP] with \"- 2\" and with \"\n",
        "            special_tokens_count = 2\n",
        "            if len(tokens_a) > max_seq_len - special_tokens_count:\n",
        "                tokens_a = tokens_a[:(max_seq_len - special_tokens_count)]\n",
        "\n",
        "        # The convention in BERT is:\n",
        "        # (a) For sequence pairs:\n",
        "        #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
        "        #  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1\n",
        "        # (b) For single sequences:\n",
        "        #  tokens:   [CLS] the dog is hairy . [SEP]\n",
        "        #  type_ids:   0   0   0   0  0     0   0\n",
        "        #\n",
        "        # Where \"type_ids\" are used to indicate whether this is the first\n",
        "        # sequence or the second sequence. The embedding vectors for `type=0` and\n",
        "        # `type=1` were learned during pre-training and are added to the wordpiece\n",
        "        # embedding vector (and position vector). This is not *strictly* necessary\n",
        "        # since the [SEP] token unambiguously separates the sequences, but it makes\n",
        "        # it easier for the model to learn the concept of sequences.\n",
        "        #\n",
        "        # For classification tasks, the first vector (corresponding to [CLS]) is\n",
        "        # used as as the \"sentence vector\". Note that this only makes sense because\n",
        "        # the entire model is fine-tuned.\n",
        "        tokens = tokens_a + [sep_token]\n",
        "        segment_ids = [sequence_a_segment_id] * len(tokens)\n",
        "\n",
        "        if tokens_b:\n",
        "            tokens += tokens_b + [sep_token]\n",
        "            segment_ids += [sequence_b_segment_id] * (len(tokens_b) + 1)\n",
        "\n",
        "        tokens = [cls_token] + tokens\n",
        "        segment_ids = [cls_token_segment_id] + segment_ids\n",
        "\n",
        "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "        # tokens are attended to.\n",
        "        input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
        "\n",
        "        # Zero-pad up to the sequence length.\n",
        "        padding_length = max_seq_len - len(input_ids)\n",
        "        input_ids = input_ids + ([pad_token] * padding_length)\n",
        "        input_mask = input_mask + \\\n",
        "                     ([0 if mask_padding_with_zero else 1] * padding_length)\n",
        "        segment_ids = segment_ids + \\\n",
        "                      ([pad_token_segment_id] * padding_length)\n",
        "\n",
        "        #add attention mask for entities as well\n",
        "        e1_mask = [0 for i in range(len(input_mask))]\n",
        "\n",
        "        e2_mask = [0 for i in range(len(input_mask))]\n",
        "\n",
        "        for i in range(e11_p, e12_p):\n",
        "            e1_mask[i] = 1\n",
        "        for i in range(e21_p, e22_p):\n",
        "            e2_mask[i] = 1\n",
        "\n",
        "        assert len(input_ids) == max_seq_len\n",
        "        assert len(input_mask) == max_seq_len\n",
        "        assert len(segment_ids) == max_seq_len\n",
        "  \n",
        "        label_id = int(example.label)\n",
        "\n",
        "        if ex_index < 5:\n",
        "            logger.info(\"*** Example ***\")\n",
        "            logger.info(\"guid: %s\" % (example.guid))\n",
        "            logger.info(\"tokens: %s\" % \" \".join(\n",
        "                [str(x) for x in tokens]))\n",
        "            logger.info(\"input_ids: %s\" %\n",
        "                        \" \".join([str(x) for x in input_ids]))\n",
        "            logger.info(\"input_mask: %s\" %\n",
        "                        \" \".join([str(x) for x in input_mask]))\n",
        "            if use_entity_indicator:\n",
        "                logger.info(\"e11_p: %s\" % e11_p)\n",
        "                logger.info(\"e12_p: %s\" % e12_p)\n",
        "                logger.info(\"e21_p: %s\" % e21_p)\n",
        "                logger.info(\"e22_p: %s\" % e22_p)\n",
        "                logger.info(\"e1_mask: %s\" %\n",
        "                            \" \".join([str(x) for x in e1_mask]))\n",
        "                logger.info(\"e2_mask: %s\" %\n",
        "                            \" \".join([str(x) for x in e2_mask]))\n",
        "            logger.info(\"segment_ids: %s\" %\n",
        "                        \" \".join([str(x) for x in segment_ids]))\n",
        "            logger.info(\"label: %s (id = %d)\" % (example.label, label_id))\n",
        "\n",
        "        features.append( InputFeatures(input_ids=input_ids,input_mask=input_mask,e11_p=e11_p,e12_p=e12_p, e21_p=e21_p, e22_p=e22_p,\n",
        "                          e1_mask=e1_mask,e2_mask=e2_mask, segment_ids=segment_ids,label_id=label_id))\n",
        "    return features"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtvdYGP0_km6"
      },
      "source": [
        "import os\n",
        "\n",
        "# Get the training data from the data folder, hosted on google drive:\n",
        "data_folder = '/content/gdrive/MyDrive/Colab Notebooks/R-BERT/data'\n",
        "examples = get_train_examples(data_folder)\n",
        "features = convert_examples_to_features(\n",
        "    examples, labels, max_seq_len, tokenizer)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5bSF9YdpxVh"
      },
      "source": [
        "*Convert* the features to tensors and make a tensor data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zF2wIkNI1eO"
      },
      "source": [
        "import torch \n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler,TensorDataset\n",
        "\n",
        "all_input_ids = torch.tensor(\n",
        "        [f.input_ids for f in features], dtype=torch.long)\n",
        "all_input_mask = torch.tensor(\n",
        "    [f.input_mask for f in features], dtype=torch.long)\n",
        "all_segment_ids = torch.tensor(\n",
        "    [f.segment_ids for f in features], dtype=torch.long)\n",
        "\n",
        "#also for entities\n",
        "all_e1_mask = torch.tensor(\n",
        "    [f.e1_mask for f in features], dtype=torch.long)\n",
        "all_e2_mask = torch.tensor(\n",
        "    [f.e2_mask for f in features], dtype=torch.long) \n",
        "\n",
        "all_label_ids = torch.tensor(\n",
        "        [f.label_id for f in features], dtype=torch.long)\n",
        "\n",
        "dataset = TensorDataset(all_input_ids, all_input_mask,\n",
        "                            all_segment_ids, all_label_ids, all_e1_mask, all_e2_mask)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocsdh3vD1bow"
      },
      "source": [
        "# 3. Preparing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rfyz43huJHaz"
      },
      "source": [
        "# Configuration parameters:\n",
        "\n",
        "# batch size (low to save memory):\n",
        "per_gpu_train_batch_size = 4\n",
        "n_gpu = torch.cuda.device_count()\n",
        "\n",
        "# the base BERT model (smaller, to save memory)\n",
        "pretrained_model_name='bert-base-uncased'\n",
        "\n",
        "# parameters for gradient descent:\n",
        "max_steps=-1\n",
        "gradient_accumulation_steps=1 \n",
        "\n",
        "# Number of training epochs:\n",
        "num_train_epochs=5.0\n",
        "\n",
        "# Name of task for Bert:\n",
        "task_name = 'semeval'\n",
        "\n",
        "# hyperparameter for regularization\n",
        "l2_reg_lambda=5e-3\n",
        "local_rank=-1\n",
        "no_cuda=False\n",
        "\n",
        "train_batch_size = per_gpu_train_batch_size * \\\n",
        "        max(1, n_gpu)\n",
        "\n",
        "# For sampling during the training:\n",
        "train_sampler = RandomSampler(dataset)\n",
        "train_dataloader = DataLoader(\n",
        "        dataset, sampler=train_sampler, batch_size=train_batch_size)\n",
        "\n",
        "# total number of steps for training:\n",
        "t_total = len(train_dataloader) // gradient_accumulation_steps * num_train_epochs"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_UwqeLDhig7"
      },
      "source": [
        "# 4. Load the Bert customized for relation extraction (R-Bert)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkOIYVQ-JTzL"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import (BertModel, BertPreTrainedModel, BertTokenizer)\n",
        "from torch.nn import MSELoss, CrossEntropyLoss\n",
        "\n",
        "def l2_loss(parameters):\n",
        "  '''Calculates L2 loss (euclidian length) of 'parameters' vector.'''\n",
        "  return torch.sum(   torch.tensor([torch.sum(p ** 2) / 2 for p in parameters if p.requires_grad ]))\n",
        "\n",
        "\n",
        "# Huggingface Transformers Class for BERT Sequence Classification\n",
        "class BertForSequenceClassification(BertPreTrainedModel):\n",
        "    \"\"\"\n",
        "        **labels**: (`optional`) ``torch.LongTensor`` of shape ``(batch_size,)``:\n",
        "            Labels for computing the sequence classification/regression loss.\n",
        "            Indices should be in ``[0, ..., config.num_labels - 1]``.\n",
        "            If ``config.num_labels == 1`` a regression loss is computed (Mean-Square loss),\n",
        "            If ``config.num_labels > 1`` a classification loss is computed (Cross-Entropy).\n",
        "\n",
        "    Outputs: `Tuple` comprising various elements depending on the configuration (config) and inputs:\n",
        "        **loss**: (`optional`, returned when ``labels`` is provided) ``torch.FloatTensor`` of shape ``(1,)``:\n",
        "            Classification (or regression if config.num_labels==1) loss.\n",
        "        **logits**: ``torch.FloatTensor`` of shape ``(batch_size, config.num_labels)``\n",
        "            Classification (or regression if config.num_labels==1) scores (before SoftMax).\n",
        "        **hidden_states**: (`optional`, returned when ``config.output_hidden_states=True``)\n",
        "            list of ``torch.FloatTensor`` (one for the output of each layer + the output of the embeddings)\n",
        "            of shape ``(batch_size, sequence_length, hidden_size)``:\n",
        "            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n",
        "        **attentions**: (`optional`, returned when ``config.output_attentions=True``)\n",
        "            list of ``torch.FloatTensor`` (one for each layer) of shape ``(batch_size, num_heads, sequence_length, sequence_length)``:\n",
        "            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention heads.\n",
        "\n",
        "    Examples::\n",
        "\n",
        "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        model = BertForSequenceClassification.from_pretrained(\n",
        "            'bert-base-uncased')\n",
        "        input_ids = torch.tensor(tokenizer.encode(\n",
        "            \"Hello, my dog is cute\")).unsqueeze(0)  # Batch size 1\n",
        "        labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
        "        outputs = model(input_ids, labels=labels)\n",
        "        loss, logits = outputs[:2]\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(BertForSequenceClassification, self).__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "        self.l2_reg_lambda = config.l2_reg_lambda\n",
        "        self.bert = BertModel(config)\n",
        "        self.latent_entity_typing = config.latent_entity_typing\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        classifier_size = config.hidden_size*3\n",
        "        self.classifier = nn.Linear(\n",
        "            classifier_size, self.config.num_labels)\n",
        "        self.latent_size = config.hidden_size\n",
        "        self.latent_type = nn.Parameter(torch.FloatTensor(\n",
        "            3, config.hidden_size), requires_grad=True)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    # Customized forward step, for relation extraction\n",
        "    # Does the extra steps required, as described in the paper.\n",
        "    # Enriching Pre-trained Language Model with Entity Information for Relation Classification https://arxiv.org/abs/1905.08284.\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, e1_mask=None, e2_mask=None, labels=None,\n",
        "                position_ids=None, head_mask=None):\n",
        "\n",
        "        outputs = self.bert(input_ids, position_ids=position_ids, token_type_ids=token_type_ids,\n",
        "                            attention_mask=attention_mask, head_mask=head_mask)\n",
        "        pooled_output = outputs[1]\n",
        "        sequence_output = outputs[0]\n",
        "\n",
        "        def extract_entity(sequence_output, e_mask):\n",
        "            extended_e_mask = e_mask.unsqueeze(1)\n",
        "            extended_e_mask = torch.bmm(\n",
        "                extended_e_mask.float(), sequence_output).squeeze(1)\n",
        "            return extended_e_mask.float()\n",
        "\n",
        "        e1_h = extract_entity(sequence_output, e1_mask)\n",
        "        e2_h = extract_entity(sequence_output, e2_mask)\n",
        "        context = self.dropout(pooled_output)\n",
        "        pooled_output = torch.cat([context, e1_h, e2_h], dim=-1)\n",
        "\n",
        "        # Extra logit layer on top of BERT,  in order to do relation extraction:\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        # add hidden states and attention\n",
        "        outputs = (logits,) + outputs[2:]\n",
        "\n",
        "        device = logits.get_device()\n",
        "        l2 = l2_loss(self.parameters())\n",
        "\n",
        "        if device >= 0:\n",
        "            l2 = l2.to(device)\n",
        "        loss = l2 * self.l2_reg_lambda\n",
        "        if labels is not None:\n",
        "\n",
        "            # transform to plausible probabilities,  between 0 and 1:            \n",
        "            probabilities = F.softmax(logits, dim=-1)\n",
        "            log_probs = F.log_softmax(logits, dim=-1)\n",
        "\n",
        "            # Do one hot encoding:\n",
        "            one_hot_labels = F.one_hot(labels, num_classes=self.num_labels)\n",
        "            if device >= 0:\n",
        "                one_hot_labels = one_hot_labels.to(device)\n",
        "\n",
        "            # Calculate loss:\n",
        "            dist = one_hot_labels[:, 1:].float() * log_probs[:, 1:]\n",
        "            example_loss_except_other, _ = dist.min(dim=-1)\n",
        "            per_example_loss = - example_loss_except_other.mean()\n",
        "\n",
        "            rc_probabilities = probabilities - probabilities * one_hot_labels.float()\n",
        "            second_pre,  _ = rc_probabilities[:, 1:].max(dim=-1)\n",
        "            rc_loss = - (1 - second_pre).log().mean()\n",
        "\n",
        "            loss += per_example_loss + 5 * rc_loss\n",
        "\n",
        "            outputs = (loss,) + outputs\n",
        "\n",
        "        return outputs  # (loss), logits, (hidden_states), (attentions)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hOXeBlmJyUL",
        "outputId": "1f851061-2c14-466e-ecf6-51153034a59d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "b28bf304eb16457d994cd7b08c4ca982",
            "5db166ca820a41899b519a79cf901813",
            "3a86a23d52354d82817e422141f1a208",
            "272af323603843299d0ecfe31c3ab647",
            "e1b0a14bacb948e38e8b9375165a1ae0",
            "30a5c1ae163d4124be7136115b972052",
            "27ed2605b6ec4d6c8ec1ef31355d3b78",
            "27363542439a4339b4b630063f25b783",
            "f67ae90202ec4b239ee9a08e3dd114f4",
            "6554a2f667974b19b2301c3ff988eeac",
            "0b6b5fa5db164bb8b4155aa6c3c3f724"
          ]
        }
      },
      "source": [
        "# Make config variable for the model:\n",
        "bertconfig = BertConfig.from_pretrained(\n",
        "        pretrained_model_name, num_labels=n_labels, finetuning_task=task_name)\n",
        "\n",
        "bertconfig.l2_reg_lambda = l2_reg_lambda\n",
        "bertconfig.latent_entity_typing = False\n",
        "bertconfig.num_classes = n_labels\n",
        "\n",
        "# Load the model:\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "        pretrained_model_name, config=bertconfig)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b28bf304eb16457d994cd7b08c4ca982"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['latent_type', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-8S8HXOhxy9"
      },
      "source": [
        "# 5. Get ready for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7V6XGt3nK8aR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3baf62b-da4c-4aa4-dda9-e0127ba410b9"
      },
      "source": [
        "# Prepare optimizer and schedule (linear warmup and decay)\n",
        "\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "# Hyperparameters for the optimizer:\n",
        "max_grad_norm = 1.0\n",
        "learning_rate=2e-5\n",
        "adam_epsilon=1e-8\n",
        "warmup_steps=0\n",
        "weight_decay=0.9\n",
        "\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters()\n",
        "                if not any(nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n",
        "    {'params': [p for n, p in model.named_parameters()\n",
        "                if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "# Load optimizer and scheduler:\n",
        "optimizer = AdamW(optimizer_grouped_parameters,\n",
        "                  lr=learning_rate, eps=adam_epsilon)\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total)\n",
        "\n",
        "# Parallelize in case we have multiple GPUs:\n",
        "if n_gpu > 1:\n",
        "    model = torch.nn.DataParallel(model)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1O5uk_vK8kx",
        "outputId": "6cf85497-1003-41e5-9e2a-f77faa9789af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Prepare for trainig:\n",
        "from tqdm import tqdm, trange\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "#  Random seed for reproducability\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "global_step = 0\n",
        "tr_loss, logging_loss = 0.0, 0.0\n",
        "model.zero_grad()\n",
        "train_iterator = trange(int(num_train_epochs),\n",
        "                        desc=\"Epoch\", disable=local_rank not in [-1, 0])\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:   0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUAKtXGzLWx4",
        "outputId": "2484a58c-1f07-4a1a-f694-fd4ad92d0193",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# put the model to the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() and not no_cuda else \"cpu\")\n",
        "model.to(device)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=2304, out_features=18, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZf9v1dOh2aD"
      },
      "source": [
        "# 6. Train!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAsevK9qLh1A",
        "outputId": "64082407-00fc-491d-fe66-e1159dcdddbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Loops through the training set for a few epochs and backpropagate\n",
        "\n",
        "# Collect the loss values:\n",
        "loss_values = []\n",
        "\n",
        "seed = 123456\n",
        "set_seed(seed)\n",
        "\n",
        "for _ in train_iterator:\n",
        "    epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\",\n",
        "                          disable=local_rank not in [-1, 0])\n",
        "    \n",
        "    # For each epoch,  split into batches and train!\n",
        "\n",
        "    for step, batch in enumerate(epoch_iterator):\n",
        "        model.train()\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'token_type_ids': batch[2],\n",
        "                  'labels':      batch[3],\n",
        "                  'e1_mask': batch[4],\n",
        "                  'e2_mask': batch[5],\n",
        "                  }\n",
        "\n",
        "        outputs = model(**inputs)\n",
        "        # model outputs are always tuple in transformers\n",
        "        \n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Collect the loss:\n",
        "        loss_values.append(loss)\n",
        "        \n",
        "        if n_gpu > 1:\n",
        "            loss = loss.mean()  \n",
        "            # mean() to average on multi-gpu parallel training\n",
        "        if gradient_accumulation_steps > 1:\n",
        "            loss = loss / gradient_accumulation_steps\n",
        "        \n",
        "        # Back propagate\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            model.parameters(), max_grad_norm)\n",
        "\n",
        "        tr_loss += loss.item()\n",
        "        if (step + 1) % gradient_accumulation_steps == 0:\n",
        "\n",
        "            # Take a step! \n",
        "            optimizer.step()\n",
        "            scheduler.step()              \n",
        "            # Update learning rate schedule\n",
        "            model.zero_grad()\n",
        "            global_step += 1\n",
        "\n",
        "        if max_steps > 0 and global_step > max_steps:\n",
        "            # We're done!\n",
        "            epoch_iterator.close()\n",
        "            break\n",
        "    if max_steps > 0 and global_step > max_steps:\n",
        "        # We're done!\n",
        "        train_iterator.close()\n",
        "        break"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:   0%|          | 0/138 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1%|          | 1/138 [00:02<06:10,  2.70s/it]\u001b[A\n",
            "Iteration:   1%|▏         | 2/138 [00:02<02:46,  1.22s/it]\u001b[A\n",
            "Iteration:   2%|▏         | 3/138 [00:03<01:39,  1.36it/s]\u001b[A\n",
            "Iteration:   3%|▎         | 4/138 [00:03<01:08,  1.96it/s]\u001b[A\n",
            "Iteration:   4%|▎         | 5/138 [00:03<00:51,  2.61it/s]\u001b[A\n",
            "Iteration:   4%|▍         | 6/138 [00:03<00:40,  3.24it/s]\u001b[A\n",
            "Iteration:   5%|▌         | 7/138 [00:03<00:34,  3.84it/s]\u001b[A\n",
            "Iteration:   6%|▌         | 8/138 [00:03<00:29,  4.36it/s]\u001b[A\n",
            "Iteration:   7%|▋         | 9/138 [00:04<00:26,  4.78it/s]\u001b[A\n",
            "Iteration:   7%|▋         | 10/138 [00:04<00:24,  5.14it/s]\u001b[A\n",
            "Iteration:   8%|▊         | 11/138 [00:04<00:23,  5.42it/s]\u001b[A\n",
            "Iteration:   9%|▊         | 12/138 [00:04<00:22,  5.63it/s]\u001b[A\n",
            "Iteration:   9%|▉         | 13/138 [00:04<00:21,  5.75it/s]\u001b[A\n",
            "Iteration:  10%|█         | 14/138 [00:04<00:21,  5.85it/s]\u001b[A\n",
            "Iteration:  11%|█         | 15/138 [00:04<00:20,  5.97it/s]\u001b[A\n",
            "Iteration:  12%|█▏        | 16/138 [00:05<00:20,  6.00it/s]\u001b[A\n",
            "Iteration:  12%|█▏        | 17/138 [00:05<00:20,  6.04it/s]\u001b[A\n",
            "Iteration:  13%|█▎        | 18/138 [00:05<00:19,  6.06it/s]\u001b[A\n",
            "Iteration:  14%|█▍        | 19/138 [00:05<00:19,  6.11it/s]\u001b[A\n",
            "Iteration:  14%|█▍        | 20/138 [00:05<00:19,  6.11it/s]\u001b[A\n",
            "Iteration:  15%|█▌        | 21/138 [00:05<00:19,  6.14it/s]\u001b[A\n",
            "Iteration:  16%|█▌        | 22/138 [00:06<00:18,  6.14it/s]\u001b[A\n",
            "Iteration:  17%|█▋        | 23/138 [00:06<00:18,  6.14it/s]\u001b[A\n",
            "Iteration:  17%|█▋        | 24/138 [00:06<00:18,  6.12it/s]\u001b[A\n",
            "Iteration:  18%|█▊        | 25/138 [00:06<00:18,  6.13it/s]\u001b[A\n",
            "Iteration:  19%|█▉        | 26/138 [00:06<00:18,  6.14it/s]\u001b[A\n",
            "Iteration:  20%|█▉        | 27/138 [00:06<00:18,  6.15it/s]\u001b[A\n",
            "Iteration:  20%|██        | 28/138 [00:07<00:17,  6.14it/s]\u001b[A\n",
            "Iteration:  21%|██        | 29/138 [00:07<00:17,  6.15it/s]\u001b[A\n",
            "Iteration:  22%|██▏       | 30/138 [00:07<00:17,  6.16it/s]\u001b[A\n",
            "Iteration:  22%|██▏       | 31/138 [00:07<00:17,  6.16it/s]\u001b[A\n",
            "Iteration:  23%|██▎       | 32/138 [00:07<00:17,  6.16it/s]\u001b[A\n",
            "Iteration:  24%|██▍       | 33/138 [00:07<00:17,  6.17it/s]\u001b[A\n",
            "Iteration:  25%|██▍       | 34/138 [00:08<00:16,  6.16it/s]\u001b[A\n",
            "Iteration:  25%|██▌       | 35/138 [00:08<00:16,  6.23it/s]\u001b[A\n",
            "Iteration:  26%|██▌       | 36/138 [00:08<00:16,  6.17it/s]\u001b[A\n",
            "Iteration:  27%|██▋       | 37/138 [00:08<00:16,  6.13it/s]\u001b[A\n",
            "Iteration:  28%|██▊       | 38/138 [00:08<00:16,  6.10it/s]\u001b[A\n",
            "Iteration:  28%|██▊       | 39/138 [00:08<00:16,  6.11it/s]\u001b[A\n",
            "Iteration:  29%|██▉       | 40/138 [00:09<00:16,  6.11it/s]\u001b[A\n",
            "Iteration:  30%|██▉       | 41/138 [00:09<00:15,  6.11it/s]\u001b[A\n",
            "Iteration:  30%|███       | 42/138 [00:09<00:15,  6.13it/s]\u001b[A\n",
            "Iteration:  31%|███       | 43/138 [00:09<00:15,  6.15it/s]\u001b[A\n",
            "Iteration:  32%|███▏      | 44/138 [00:09<00:15,  6.17it/s]\u001b[A\n",
            "Iteration:  33%|███▎      | 45/138 [00:09<00:15,  6.16it/s]\u001b[A\n",
            "Iteration:  33%|███▎      | 46/138 [00:10<00:14,  6.14it/s]\u001b[A\n",
            "Iteration:  34%|███▍      | 47/138 [00:10<00:14,  6.11it/s]\u001b[A\n",
            "Iteration:  35%|███▍      | 48/138 [00:10<00:14,  6.09it/s]\u001b[A\n",
            "Iteration:  36%|███▌      | 49/138 [00:10<00:14,  6.11it/s]\u001b[A\n",
            "Iteration:  36%|███▌      | 50/138 [00:10<00:14,  6.15it/s]\u001b[A\n",
            "Iteration:  37%|███▋      | 51/138 [00:10<00:14,  6.16it/s]\u001b[A\n",
            "Iteration:  38%|███▊      | 52/138 [00:11<00:14,  6.14it/s]\u001b[A\n",
            "Iteration:  38%|███▊      | 53/138 [00:11<00:13,  6.13it/s]\u001b[A\n",
            "Iteration:  39%|███▉      | 54/138 [00:11<00:13,  6.13it/s]\u001b[A\n",
            "Iteration:  40%|███▉      | 55/138 [00:11<00:13,  6.12it/s]\u001b[A\n",
            "Iteration:  41%|████      | 56/138 [00:11<00:13,  6.10it/s]\u001b[A\n",
            "Iteration:  41%|████▏     | 57/138 [00:11<00:13,  6.06it/s]\u001b[A\n",
            "Iteration:  42%|████▏     | 58/138 [00:12<00:13,  6.04it/s]\u001b[A\n",
            "Iteration:  43%|████▎     | 59/138 [00:12<00:13,  6.07it/s]\u001b[A\n",
            "Iteration:  43%|████▎     | 60/138 [00:12<00:12,  6.09it/s]\u001b[A\n",
            "Iteration:  44%|████▍     | 61/138 [00:12<00:12,  6.11it/s]\u001b[A\n",
            "Iteration:  45%|████▍     | 62/138 [00:12<00:12,  6.14it/s]\u001b[A\n",
            "Iteration:  46%|████▌     | 63/138 [00:12<00:12,  6.16it/s]\u001b[A\n",
            "Iteration:  46%|████▋     | 64/138 [00:12<00:12,  6.15it/s]\u001b[A\n",
            "Iteration:  47%|████▋     | 65/138 [00:13<00:11,  6.10it/s]\u001b[A\n",
            "Iteration:  48%|████▊     | 66/138 [00:13<00:11,  6.10it/s]\u001b[A\n",
            "Iteration:  49%|████▊     | 67/138 [00:13<00:11,  6.10it/s]\u001b[A\n",
            "Iteration:  49%|████▉     | 68/138 [00:13<00:11,  6.06it/s]\u001b[A\n",
            "Iteration:  50%|█████     | 69/138 [00:13<00:11,  6.04it/s]\u001b[A\n",
            "Iteration:  51%|█████     | 70/138 [00:13<00:11,  6.06it/s]\u001b[A\n",
            "Iteration:  51%|█████▏    | 71/138 [00:14<00:11,  6.06it/s]\u001b[A\n",
            "Iteration:  52%|█████▏    | 72/138 [00:14<00:10,  6.05it/s]\u001b[A\n",
            "Iteration:  53%|█████▎    | 73/138 [00:14<00:10,  6.06it/s]\u001b[A\n",
            "Iteration:  54%|█████▎    | 74/138 [00:14<00:10,  6.10it/s]\u001b[A\n",
            "Iteration:  54%|█████▍    | 75/138 [00:14<00:10,  6.08it/s]\u001b[A\n",
            "Iteration:  55%|█████▌    | 76/138 [00:14<00:10,  6.09it/s]\u001b[A\n",
            "Iteration:  56%|█████▌    | 77/138 [00:15<00:10,  6.09it/s]\u001b[A\n",
            "Iteration:  57%|█████▋    | 78/138 [00:15<00:09,  6.03it/s]\u001b[A\n",
            "Iteration:  57%|█████▋    | 79/138 [00:15<00:09,  6.05it/s]\u001b[A\n",
            "Iteration:  58%|█████▊    | 80/138 [00:15<00:09,  6.03it/s]\u001b[A\n",
            "Iteration:  59%|█████▊    | 81/138 [00:15<00:09,  5.98it/s]\u001b[A\n",
            "Iteration:  59%|█████▉    | 82/138 [00:15<00:09,  5.98it/s]\u001b[A\n",
            "Iteration:  60%|██████    | 83/138 [00:16<00:09,  6.01it/s]\u001b[A\n",
            "Iteration:  61%|██████    | 84/138 [00:16<00:08,  6.04it/s]\u001b[A\n",
            "Iteration:  62%|██████▏   | 85/138 [00:16<00:08,  6.08it/s]\u001b[A\n",
            "Iteration:  62%|██████▏   | 86/138 [00:16<00:08,  6.08it/s]\u001b[A\n",
            "Iteration:  63%|██████▎   | 87/138 [00:16<00:08,  6.11it/s]\u001b[A\n",
            "Iteration:  64%|██████▍   | 88/138 [00:16<00:08,  6.13it/s]\u001b[A\n",
            "Iteration:  64%|██████▍   | 89/138 [00:17<00:08,  6.12it/s]\u001b[A\n",
            "Iteration:  65%|██████▌   | 90/138 [00:17<00:07,  6.07it/s]\u001b[A\n",
            "Iteration:  66%|██████▌   | 91/138 [00:17<00:07,  6.12it/s]\u001b[A\n",
            "Iteration:  67%|██████▋   | 92/138 [00:17<00:07,  6.14it/s]\u001b[A\n",
            "Iteration:  67%|██████▋   | 93/138 [00:17<00:07,  6.16it/s]\u001b[A\n",
            "Iteration:  68%|██████▊   | 94/138 [00:17<00:07,  6.14it/s]\u001b[A\n",
            "Iteration:  69%|██████▉   | 95/138 [00:18<00:06,  6.16it/s]\u001b[A\n",
            "Iteration:  70%|██████▉   | 96/138 [00:18<00:06,  6.13it/s]\u001b[A\n",
            "Iteration:  70%|███████   | 97/138 [00:18<00:06,  6.15it/s]\u001b[A\n",
            "Iteration:  71%|███████   | 98/138 [00:18<00:06,  6.13it/s]\u001b[A\n",
            "Iteration:  72%|███████▏  | 99/138 [00:18<00:06,  6.12it/s]\u001b[A\n",
            "Iteration:  72%|███████▏  | 100/138 [00:18<00:06,  6.13it/s]\u001b[A\n",
            "Iteration:  73%|███████▎  | 101/138 [00:19<00:06,  6.09it/s]\u001b[A\n",
            "Iteration:  74%|███████▍  | 102/138 [00:19<00:05,  6.04it/s]\u001b[A\n",
            "Iteration:  75%|███████▍  | 103/138 [00:19<00:05,  6.05it/s]\u001b[A\n",
            "Iteration:  75%|███████▌  | 104/138 [00:19<00:05,  6.06it/s]\u001b[A\n",
            "Iteration:  76%|███████▌  | 105/138 [00:19<00:05,  6.06it/s]\u001b[A\n",
            "Iteration:  77%|███████▋  | 106/138 [00:19<00:05,  6.11it/s]\u001b[A\n",
            "Iteration:  78%|███████▊  | 107/138 [00:20<00:05,  6.12it/s]\u001b[A\n",
            "Iteration:  78%|███████▊  | 108/138 [00:20<00:04,  6.10it/s]\u001b[A\n",
            "Iteration:  79%|███████▉  | 109/138 [00:20<00:04,  6.06it/s]\u001b[A\n",
            "Iteration:  80%|███████▉  | 110/138 [00:20<00:04,  6.03it/s]\u001b[A\n",
            "Iteration:  80%|████████  | 111/138 [00:20<00:04,  6.02it/s]\u001b[A\n",
            "Iteration:  81%|████████  | 112/138 [00:20<00:04,  6.00it/s]\u001b[A\n",
            "Iteration:  82%|████████▏ | 113/138 [00:21<00:04,  6.05it/s]\u001b[A\n",
            "Iteration:  83%|████████▎ | 114/138 [00:21<00:03,  6.07it/s]\u001b[A\n",
            "Iteration:  83%|████████▎ | 115/138 [00:21<00:03,  6.09it/s]\u001b[A\n",
            "Iteration:  84%|████████▍ | 116/138 [00:21<00:03,  6.11it/s]\u001b[A\n",
            "Iteration:  85%|████████▍ | 117/138 [00:21<00:03,  6.10it/s]\u001b[A\n",
            "Iteration:  86%|████████▌ | 118/138 [00:21<00:03,  6.08it/s]\u001b[A\n",
            "Iteration:  86%|████████▌ | 119/138 [00:22<00:03,  6.08it/s]\u001b[A\n",
            "Iteration:  87%|████████▋ | 120/138 [00:22<00:02,  6.05it/s]\u001b[A\n",
            "Iteration:  88%|████████▊ | 121/138 [00:22<00:02,  6.04it/s]\u001b[A\n",
            "Iteration:  88%|████████▊ | 122/138 [00:22<00:02,  6.04it/s]\u001b[A\n",
            "Iteration:  89%|████████▉ | 123/138 [00:22<00:02,  6.06it/s]\u001b[A\n",
            "Iteration:  90%|████████▉ | 124/138 [00:22<00:02,  6.07it/s]\u001b[A\n",
            "Iteration:  91%|█████████ | 125/138 [00:23<00:02,  6.07it/s]\u001b[A\n",
            "Iteration:  91%|█████████▏| 126/138 [00:23<00:01,  6.03it/s]\u001b[A\n",
            "Iteration:  92%|█████████▏| 127/138 [00:23<00:01,  6.04it/s]\u001b[A\n",
            "Iteration:  93%|█████████▎| 128/138 [00:23<00:01,  6.05it/s]\u001b[A\n",
            "Iteration:  93%|█████████▎| 129/138 [00:23<00:01,  6.04it/s]\u001b[A\n",
            "Iteration:  94%|█████████▍| 130/138 [00:23<00:01,  6.06it/s]\u001b[A\n",
            "Iteration:  95%|█████████▍| 131/138 [00:24<00:01,  6.02it/s]\u001b[A\n",
            "Iteration:  96%|█████████▌| 132/138 [00:24<00:00,  6.13it/s]\u001b[A\n",
            "Iteration:  96%|█████████▋| 133/138 [00:24<00:00,  6.23it/s]\u001b[A\n",
            "Iteration:  97%|█████████▋| 134/138 [00:24<00:00,  6.31it/s]\u001b[A\n",
            "Iteration:  98%|█████████▊| 135/138 [00:24<00:00,  6.35it/s]\u001b[A\n",
            "Iteration:  99%|█████████▊| 136/138 [00:24<00:00,  6.39it/s]\u001b[A\n",
            "Iteration:  99%|█████████▉| 137/138 [00:24<00:00,  6.38it/s]\u001b[A\n",
            "Iteration: 100%|██████████| 138/138 [00:25<00:00,  5.49it/s]\n",
            "Epoch:  20%|██        | 1/5 [00:31<02:06, 31.62s/it]\n",
            "Iteration:   0%|          | 0/138 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1%|          | 1/138 [00:00<00:20,  6.64it/s]\u001b[A\n",
            "Iteration:   1%|▏         | 2/138 [00:00<00:21,  6.46it/s]\u001b[A\n",
            "Iteration:   2%|▏         | 3/138 [00:00<00:20,  6.48it/s]\u001b[A\n",
            "Iteration:   3%|▎         | 4/138 [00:00<00:20,  6.47it/s]\u001b[A\n",
            "Iteration:   4%|▎         | 5/138 [00:00<00:20,  6.47it/s]\u001b[A\n",
            "Iteration:   4%|▍         | 6/138 [00:00<00:20,  6.46it/s]\u001b[A\n",
            "Iteration:   5%|▌         | 7/138 [00:01<00:20,  6.46it/s]\u001b[A\n",
            "Iteration:   6%|▌         | 8/138 [00:01<00:20,  6.47it/s]\u001b[A\n",
            "Iteration:   7%|▋         | 9/138 [00:01<00:19,  6.47it/s]\u001b[A\n",
            "Iteration:   7%|▋         | 10/138 [00:01<00:19,  6.49it/s]\u001b[A\n",
            "Iteration:   8%|▊         | 11/138 [00:01<00:19,  6.50it/s]\u001b[A\n",
            "Iteration:   9%|▊         | 12/138 [00:01<00:19,  6.48it/s]\u001b[A\n",
            "Iteration:   9%|▉         | 13/138 [00:02<00:19,  6.46it/s]\u001b[A\n",
            "Iteration:  10%|█         | 14/138 [00:02<00:19,  6.47it/s]\u001b[A\n",
            "Iteration:  11%|█         | 15/138 [00:02<00:18,  6.49it/s]\u001b[A\n",
            "Iteration:  12%|█▏        | 16/138 [00:02<00:18,  6.48it/s]\u001b[A\n",
            "Iteration:  12%|█▏        | 17/138 [00:02<00:18,  6.48it/s]\u001b[A\n",
            "Iteration:  13%|█▎        | 18/138 [00:02<00:18,  6.43it/s]\u001b[A\n",
            "Iteration:  14%|█▍        | 19/138 [00:02<00:18,  6.46it/s]\u001b[A\n",
            "Iteration:  14%|█▍        | 20/138 [00:03<00:18,  6.44it/s]\u001b[A\n",
            "Iteration:  15%|█▌        | 21/138 [00:03<00:18,  6.48it/s]\u001b[A\n",
            "Iteration:  16%|█▌        | 22/138 [00:03<00:17,  6.45it/s]\u001b[A\n",
            "Iteration:  17%|█▋        | 23/138 [00:03<00:17,  6.41it/s]\u001b[A\n",
            "Iteration:  17%|█▋        | 24/138 [00:03<00:17,  6.43it/s]\u001b[A\n",
            "Iteration:  18%|█▊        | 25/138 [00:03<00:17,  6.44it/s]\u001b[A\n",
            "Iteration:  19%|█▉        | 26/138 [00:04<00:17,  6.43it/s]\u001b[A\n",
            "Iteration:  20%|█▉        | 27/138 [00:04<00:17,  6.45it/s]\u001b[A\n",
            "Iteration:  20%|██        | 28/138 [00:04<00:17,  6.45it/s]\u001b[A\n",
            "Iteration:  21%|██        | 29/138 [00:04<00:16,  6.48it/s]\u001b[A\n",
            "Iteration:  22%|██▏       | 30/138 [00:04<00:16,  6.49it/s]\u001b[A\n",
            "Iteration:  22%|██▏       | 31/138 [00:04<00:16,  6.46it/s]\u001b[A\n",
            "Iteration:  23%|██▎       | 32/138 [00:04<00:16,  6.47it/s]\u001b[A\n",
            "Iteration:  24%|██▍       | 33/138 [00:05<00:16,  6.44it/s]\u001b[A\n",
            "Iteration:  25%|██▍       | 34/138 [00:05<00:16,  6.44it/s]\u001b[A\n",
            "Iteration:  25%|██▌       | 35/138 [00:05<00:16,  6.40it/s]\u001b[A\n",
            "Iteration:  26%|██▌       | 36/138 [00:05<00:15,  6.40it/s]\u001b[A\n",
            "Iteration:  27%|██▋       | 37/138 [00:05<00:15,  6.37it/s]\u001b[A\n",
            "Iteration:  28%|██▊       | 38/138 [00:05<00:15,  6.39it/s]\u001b[A\n",
            "Iteration:  28%|██▊       | 39/138 [00:06<00:15,  6.43it/s]\u001b[A\n",
            "Iteration:  29%|██▉       | 40/138 [00:06<00:15,  6.42it/s]\u001b[A\n",
            "Iteration:  30%|██▉       | 41/138 [00:06<00:15,  6.43it/s]\u001b[A\n",
            "Iteration:  30%|███       | 42/138 [00:06<00:14,  6.46it/s]\u001b[A\n",
            "Iteration:  31%|███       | 43/138 [00:06<00:14,  6.46it/s]\u001b[A\n",
            "Iteration:  32%|███▏      | 44/138 [00:06<00:14,  6.46it/s]\u001b[A\n",
            "Iteration:  33%|███▎      | 45/138 [00:06<00:14,  6.46it/s]\u001b[A\n",
            "Iteration:  33%|███▎      | 46/138 [00:07<00:14,  6.46it/s]\u001b[A\n",
            "Iteration:  34%|███▍      | 47/138 [00:07<00:14,  6.45it/s]\u001b[A\n",
            "Iteration:  35%|███▍      | 48/138 [00:07<00:14,  6.42it/s]\u001b[A\n",
            "Iteration:  36%|███▌      | 49/138 [00:07<00:13,  6.46it/s]\u001b[A\n",
            "Iteration:  36%|███▌      | 50/138 [00:07<00:13,  6.45it/s]\u001b[A\n",
            "Iteration:  37%|███▋      | 51/138 [00:07<00:13,  6.45it/s]\u001b[A\n",
            "Iteration:  38%|███▊      | 52/138 [00:08<00:13,  6.45it/s]\u001b[A\n",
            "Iteration:  38%|███▊      | 53/138 [00:08<00:13,  6.40it/s]\u001b[A\n",
            "Iteration:  39%|███▉      | 54/138 [00:08<00:13,  6.40it/s]\u001b[A\n",
            "Iteration:  40%|███▉      | 55/138 [00:08<00:12,  6.42it/s]\u001b[A\n",
            "Iteration:  41%|████      | 56/138 [00:08<00:12,  6.43it/s]\u001b[A\n",
            "Iteration:  41%|████▏     | 57/138 [00:08<00:12,  6.38it/s]\u001b[A\n",
            "Iteration:  42%|████▏     | 58/138 [00:09<00:12,  6.39it/s]\u001b[A\n",
            "Iteration:  43%|████▎     | 59/138 [00:09<00:12,  6.41it/s]\u001b[A\n",
            "Iteration:  43%|████▎     | 60/138 [00:09<00:12,  6.41it/s]\u001b[A\n",
            "Iteration:  44%|████▍     | 61/138 [00:09<00:12,  6.39it/s]\u001b[A\n",
            "Iteration:  45%|████▍     | 62/138 [00:09<00:11,  6.43it/s]\u001b[A\n",
            "Iteration:  46%|████▌     | 63/138 [00:09<00:11,  6.41it/s]\u001b[A\n",
            "Iteration:  46%|████▋     | 64/138 [00:09<00:11,  6.38it/s]\u001b[A\n",
            "Iteration:  47%|████▋     | 65/138 [00:10<00:11,  6.38it/s]\u001b[A\n",
            "Iteration:  48%|████▊     | 66/138 [00:10<00:11,  6.40it/s]\u001b[A\n",
            "Iteration:  49%|████▊     | 67/138 [00:10<00:11,  6.42it/s]\u001b[A\n",
            "Iteration:  49%|████▉     | 68/138 [00:10<00:10,  6.44it/s]\u001b[A\n",
            "Iteration:  50%|█████     | 69/138 [00:10<00:10,  6.43it/s]\u001b[A\n",
            "Iteration:  51%|█████     | 70/138 [00:10<00:10,  6.43it/s]\u001b[A\n",
            "Iteration:  51%|█████▏    | 71/138 [00:11<00:10,  6.42it/s]\u001b[A\n",
            "Iteration:  52%|█████▏    | 72/138 [00:11<00:10,  6.41it/s]\u001b[A\n",
            "Iteration:  53%|█████▎    | 73/138 [00:11<00:10,  6.38it/s]\u001b[A\n",
            "Iteration:  54%|█████▎    | 74/138 [00:11<00:10,  6.38it/s]\u001b[A\n",
            "Iteration:  54%|█████▍    | 75/138 [00:11<00:09,  6.38it/s]\u001b[A\n",
            "Iteration:  55%|█████▌    | 76/138 [00:11<00:09,  6.39it/s]\u001b[A\n",
            "Iteration:  56%|█████▌    | 77/138 [00:11<00:09,  6.38it/s]\u001b[A\n",
            "Iteration:  57%|█████▋    | 78/138 [00:12<00:09,  6.38it/s]\u001b[A\n",
            "Iteration:  57%|█████▋    | 79/138 [00:12<00:09,  6.43it/s]\u001b[A\n",
            "Iteration:  58%|█████▊    | 80/138 [00:12<00:09,  6.41it/s]\u001b[A\n",
            "Iteration:  59%|█████▊    | 81/138 [00:12<00:08,  6.44it/s]\u001b[A\n",
            "Iteration:  59%|█████▉    | 82/138 [00:12<00:08,  6.42it/s]\u001b[A\n",
            "Iteration:  60%|██████    | 83/138 [00:12<00:08,  6.38it/s]\u001b[A\n",
            "Iteration:  61%|██████    | 84/138 [00:13<00:08,  6.37it/s]\u001b[A\n",
            "Iteration:  62%|██████▏   | 85/138 [00:13<00:08,  6.31it/s]\u001b[A\n",
            "Iteration:  62%|██████▏   | 86/138 [00:13<00:08,  6.34it/s]\u001b[A\n",
            "Iteration:  63%|██████▎   | 87/138 [00:13<00:08,  6.34it/s]\u001b[A\n",
            "Iteration:  64%|██████▍   | 88/138 [00:13<00:07,  6.39it/s]\u001b[A\n",
            "Iteration:  64%|██████▍   | 89/138 [00:13<00:07,  6.38it/s]\u001b[A\n",
            "Iteration:  65%|██████▌   | 90/138 [00:14<00:07,  6.38it/s]\u001b[A\n",
            "Iteration:  66%|██████▌   | 91/138 [00:14<00:07,  6.40it/s]\u001b[A\n",
            "Iteration:  67%|██████▋   | 92/138 [00:14<00:07,  6.39it/s]\u001b[A\n",
            "Iteration:  67%|██████▋   | 93/138 [00:14<00:07,  6.39it/s]\u001b[A\n",
            "Iteration:  68%|██████▊   | 94/138 [00:14<00:06,  6.36it/s]\u001b[A\n",
            "Iteration:  69%|██████▉   | 95/138 [00:14<00:06,  6.36it/s]\u001b[A\n",
            "Iteration:  70%|██████▉   | 96/138 [00:14<00:06,  6.39it/s]\u001b[A\n",
            "Iteration:  70%|███████   | 97/138 [00:15<00:06,  6.40it/s]\u001b[A\n",
            "Iteration:  71%|███████   | 98/138 [00:15<00:06,  6.37it/s]\u001b[A\n",
            "Iteration:  72%|███████▏  | 99/138 [00:15<00:06,  6.39it/s]\u001b[A\n",
            "Iteration:  72%|███████▏  | 100/138 [00:15<00:05,  6.43it/s]\u001b[A\n",
            "Iteration:  73%|███████▎  | 101/138 [00:15<00:05,  6.40it/s]\u001b[A\n",
            "Iteration:  74%|███████▍  | 102/138 [00:15<00:05,  6.37it/s]\u001b[A\n",
            "Iteration:  75%|███████▍  | 103/138 [00:16<00:05,  6.39it/s]\u001b[A\n",
            "Iteration:  75%|███████▌  | 104/138 [00:16<00:05,  6.39it/s]\u001b[A\n",
            "Iteration:  76%|███████▌  | 105/138 [00:16<00:05,  6.37it/s]\u001b[A\n",
            "Iteration:  77%|███████▋  | 106/138 [00:16<00:05,  6.39it/s]\u001b[A\n",
            "Iteration:  78%|███████▊  | 107/138 [00:16<00:04,  6.33it/s]\u001b[A\n",
            "Iteration:  78%|███████▊  | 108/138 [00:16<00:04,  6.35it/s]\u001b[A\n",
            "Iteration:  79%|███████▉  | 109/138 [00:16<00:04,  6.35it/s]\u001b[A\n",
            "Iteration:  80%|███████▉  | 110/138 [00:17<00:04,  6.34it/s]\u001b[A\n",
            "Iteration:  80%|████████  | 111/138 [00:17<00:04,  6.37it/s]\u001b[A\n",
            "Iteration:  81%|████████  | 112/138 [00:17<00:04,  6.39it/s]\u001b[A\n",
            "Iteration:  82%|████████▏ | 113/138 [00:17<00:03,  6.43it/s]\u001b[A\n",
            "Iteration:  83%|████████▎ | 114/138 [00:17<00:03,  6.40it/s]\u001b[A\n",
            "Iteration:  83%|████████▎ | 115/138 [00:17<00:03,  6.41it/s]\u001b[A\n",
            "Iteration:  84%|████████▍ | 116/138 [00:18<00:03,  6.39it/s]\u001b[A\n",
            "Iteration:  85%|████████▍ | 117/138 [00:18<00:03,  6.41it/s]\u001b[A\n",
            "Iteration:  86%|████████▌ | 118/138 [00:18<00:03,  6.39it/s]\u001b[A\n",
            "Iteration:  86%|████████▌ | 119/138 [00:18<00:02,  6.39it/s]\u001b[A\n",
            "Iteration:  87%|████████▋ | 120/138 [00:18<00:02,  6.37it/s]\u001b[A\n",
            "Iteration:  88%|████████▊ | 121/138 [00:18<00:02,  6.36it/s]\u001b[A\n",
            "Iteration:  88%|████████▊ | 122/138 [00:19<00:02,  6.33it/s]\u001b[A\n",
            "Iteration:  89%|████████▉ | 123/138 [00:19<00:02,  6.31it/s]\u001b[A\n",
            "Iteration:  90%|████████▉ | 124/138 [00:19<00:02,  6.34it/s]\u001b[A\n",
            "Iteration:  91%|█████████ | 125/138 [00:19<00:02,  6.36it/s]\u001b[A\n",
            "Iteration:  91%|█████████▏| 126/138 [00:19<00:01,  6.36it/s]\u001b[A\n",
            "Iteration:  92%|█████████▏| 127/138 [00:19<00:01,  6.38it/s]\u001b[A\n",
            "Iteration:  93%|█████████▎| 128/138 [00:19<00:01,  6.39it/s]\u001b[A\n",
            "Iteration:  93%|█████████▎| 129/138 [00:20<00:01,  6.39it/s]\u001b[A\n",
            "Iteration:  94%|█████████▍| 130/138 [00:20<00:01,  6.39it/s]\u001b[A\n",
            "Iteration:  95%|█████████▍| 131/138 [00:20<00:01,  6.35it/s]\u001b[A\n",
            "Iteration:  96%|█████████▌| 132/138 [00:20<00:00,  6.35it/s]\u001b[A\n",
            "Iteration:  96%|█████████▋| 133/138 [00:20<00:00,  6.35it/s]\u001b[A\n",
            "Iteration:  97%|█████████▋| 134/138 [00:20<00:00,  6.32it/s]\u001b[A\n",
            "Iteration:  98%|█████████▊| 135/138 [00:21<00:00,  6.29it/s]\u001b[A\n",
            "Iteration:  99%|█████████▊| 136/138 [00:21<00:00,  6.32it/s]\u001b[A\n",
            "Iteration:  99%|█████████▉| 137/138 [00:21<00:00,  6.34it/s]\u001b[A\n",
            "Iteration: 100%|██████████| 138/138 [00:21<00:00,  6.40it/s]\n",
            "Epoch:  40%|████      | 2/5 [00:53<01:17, 25.70s/it]\n",
            "Iteration:   0%|          | 0/138 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1%|          | 1/138 [00:00<00:21,  6.52it/s]\u001b[A\n",
            "Iteration:   1%|▏         | 2/138 [00:00<00:20,  6.48it/s]\u001b[A\n",
            "Iteration:   2%|▏         | 3/138 [00:00<00:20,  6.46it/s]\u001b[A\n",
            "Iteration:   3%|▎         | 4/138 [00:00<00:20,  6.44it/s]\u001b[A\n",
            "Iteration:   4%|▎         | 5/138 [00:00<00:20,  6.41it/s]\u001b[A\n",
            "Iteration:   4%|▍         | 6/138 [00:00<00:20,  6.37it/s]\u001b[A\n",
            "Iteration:   5%|▌         | 7/138 [00:01<00:20,  6.35it/s]\u001b[A\n",
            "Iteration:   6%|▌         | 8/138 [00:01<00:20,  6.36it/s]\u001b[A\n",
            "Iteration:   7%|▋         | 9/138 [00:01<00:20,  6.40it/s]\u001b[A\n",
            "Iteration:   7%|▋         | 10/138 [00:01<00:20,  6.36it/s]\u001b[A\n",
            "Iteration:   8%|▊         | 11/138 [00:01<00:19,  6.39it/s]\u001b[A\n",
            "Iteration:   9%|▊         | 12/138 [00:01<00:19,  6.40it/s]\u001b[A\n",
            "Iteration:   9%|▉         | 13/138 [00:02<00:19,  6.36it/s]\u001b[A\n",
            "Iteration:  10%|█         | 14/138 [00:02<00:19,  6.33it/s]\u001b[A\n",
            "Iteration:  11%|█         | 15/138 [00:02<00:19,  6.35it/s]\u001b[A\n",
            "Iteration:  12%|█▏        | 16/138 [00:02<00:19,  6.35it/s]\u001b[A\n",
            "Iteration:  12%|█▏        | 17/138 [00:02<00:19,  6.34it/s]\u001b[A\n",
            "Iteration:  13%|█▎        | 18/138 [00:02<00:18,  6.32it/s]\u001b[A\n",
            "Iteration:  14%|█▍        | 19/138 [00:02<00:18,  6.28it/s]\u001b[A\n",
            "Iteration:  14%|█▍        | 20/138 [00:03<00:18,  6.31it/s]\u001b[A\n",
            "Iteration:  15%|█▌        | 21/138 [00:03<00:18,  6.32it/s]\u001b[A\n",
            "Iteration:  16%|█▌        | 22/138 [00:03<00:18,  6.32it/s]\u001b[A\n",
            "Iteration:  17%|█▋        | 23/138 [00:03<00:18,  6.32it/s]\u001b[A\n",
            "Iteration:  17%|█▋        | 24/138 [00:03<00:18,  6.32it/s]\u001b[A\n",
            "Iteration:  18%|█▊        | 25/138 [00:03<00:17,  6.33it/s]\u001b[A\n",
            "Iteration:  19%|█▉        | 26/138 [00:04<00:17,  6.36it/s]\u001b[A\n",
            "Iteration:  20%|█▉        | 27/138 [00:04<00:17,  6.35it/s]\u001b[A\n",
            "Iteration:  20%|██        | 28/138 [00:04<00:17,  6.35it/s]\u001b[A\n",
            "Iteration:  21%|██        | 29/138 [00:04<00:17,  6.35it/s]\u001b[A\n",
            "Iteration:  22%|██▏       | 30/138 [00:04<00:17,  6.35it/s]\u001b[A\n",
            "Iteration:  22%|██▏       | 31/138 [00:04<00:16,  6.33it/s]\u001b[A\n",
            "Iteration:  23%|██▎       | 32/138 [00:05<00:16,  6.34it/s]\u001b[A\n",
            "Iteration:  24%|██▍       | 33/138 [00:05<00:16,  6.35it/s]\u001b[A\n",
            "Iteration:  25%|██▍       | 34/138 [00:05<00:16,  6.35it/s]\u001b[A\n",
            "Iteration:  25%|██▌       | 35/138 [00:05<00:16,  6.35it/s]\u001b[A\n",
            "Iteration:  26%|██▌       | 36/138 [00:05<00:16,  6.28it/s]\u001b[A\n",
            "Iteration:  27%|██▋       | 37/138 [00:05<00:15,  6.32it/s]\u001b[A\n",
            "Iteration:  28%|██▊       | 38/138 [00:05<00:15,  6.32it/s]\u001b[A\n",
            "Iteration:  28%|██▊       | 39/138 [00:06<00:15,  6.32it/s]\u001b[A\n",
            "Iteration:  29%|██▉       | 40/138 [00:06<00:15,  6.32it/s]\u001b[A\n",
            "Iteration:  30%|██▉       | 41/138 [00:06<00:15,  6.36it/s]\u001b[A\n",
            "Iteration:  30%|███       | 42/138 [00:06<00:15,  6.34it/s]\u001b[A\n",
            "Iteration:  31%|███       | 43/138 [00:06<00:14,  6.35it/s]\u001b[A\n",
            "Iteration:  32%|███▏      | 44/138 [00:06<00:14,  6.34it/s]\u001b[A\n",
            "Iteration:  33%|███▎      | 45/138 [00:07<00:14,  6.36it/s]\u001b[A\n",
            "Iteration:  33%|███▎      | 46/138 [00:07<00:14,  6.35it/s]\u001b[A\n",
            "Iteration:  34%|███▍      | 47/138 [00:07<00:14,  6.32it/s]\u001b[A\n",
            "Iteration:  35%|███▍      | 48/138 [00:07<00:14,  6.29it/s]\u001b[A\n",
            "Iteration:  36%|███▌      | 49/138 [00:07<00:14,  6.34it/s]\u001b[A\n",
            "Iteration:  36%|███▌      | 50/138 [00:07<00:13,  6.38it/s]\u001b[A\n",
            "Iteration:  37%|███▋      | 51/138 [00:08<00:13,  6.35it/s]\u001b[A\n",
            "Iteration:  38%|███▊      | 52/138 [00:08<00:13,  6.34it/s]\u001b[A\n",
            "Iteration:  38%|███▊      | 53/138 [00:08<00:13,  6.31it/s]\u001b[A\n",
            "Iteration:  39%|███▉      | 54/138 [00:08<00:13,  6.34it/s]\u001b[A\n",
            "Iteration:  40%|███▉      | 55/138 [00:08<00:13,  6.34it/s]\u001b[A\n",
            "Iteration:  41%|████      | 56/138 [00:08<00:12,  6.33it/s]\u001b[A\n",
            "Iteration:  41%|████▏     | 57/138 [00:08<00:12,  6.30it/s]\u001b[A\n",
            "Iteration:  42%|████▏     | 58/138 [00:09<00:12,  6.34it/s]\u001b[A\n",
            "Iteration:  43%|████▎     | 59/138 [00:09<00:12,  6.32it/s]\u001b[A\n",
            "Iteration:  43%|████▎     | 60/138 [00:09<00:12,  6.29it/s]\u001b[A\n",
            "Iteration:  44%|████▍     | 61/138 [00:09<00:12,  6.31it/s]\u001b[A\n",
            "Iteration:  45%|████▍     | 62/138 [00:09<00:12,  6.32it/s]\u001b[A\n",
            "Iteration:  46%|████▌     | 63/138 [00:09<00:11,  6.34it/s]\u001b[A\n",
            "Iteration:  46%|████▋     | 64/138 [00:10<00:11,  6.32it/s]\u001b[A\n",
            "Iteration:  47%|████▋     | 65/138 [00:10<00:11,  6.31it/s]\u001b[A\n",
            "Iteration:  48%|████▊     | 66/138 [00:10<00:11,  6.22it/s]\u001b[A\n",
            "Iteration:  49%|████▊     | 67/138 [00:10<00:11,  6.26it/s]\u001b[A\n",
            "Iteration:  49%|████▉     | 68/138 [00:10<00:11,  6.28it/s]\u001b[A\n",
            "Iteration:  50%|█████     | 69/138 [00:10<00:10,  6.28it/s]\u001b[A\n",
            "Iteration:  51%|█████     | 70/138 [00:11<00:10,  6.31it/s]\u001b[A\n",
            "Iteration:  51%|█████▏    | 71/138 [00:11<00:10,  6.28it/s]\u001b[A\n",
            "Iteration:  52%|█████▏    | 72/138 [00:11<00:10,  6.27it/s]\u001b[A\n",
            "Iteration:  53%|█████▎    | 73/138 [00:11<00:10,  6.30it/s]\u001b[A\n",
            "Iteration:  54%|█████▎    | 74/138 [00:11<00:10,  6.31it/s]\u001b[A\n",
            "Iteration:  54%|█████▍    | 75/138 [00:11<00:10,  6.30it/s]\u001b[A\n",
            "Iteration:  55%|█████▌    | 76/138 [00:12<00:09,  6.26it/s]\u001b[A\n",
            "Iteration:  56%|█████▌    | 77/138 [00:12<00:09,  6.21it/s]\u001b[A\n",
            "Iteration:  57%|█████▋    | 78/138 [00:12<00:09,  6.21it/s]\u001b[A\n",
            "Iteration:  57%|█████▋    | 79/138 [00:12<00:09,  6.19it/s]\u001b[A\n",
            "Iteration:  58%|█████▊    | 80/138 [00:12<00:09,  6.18it/s]\u001b[A\n",
            "Iteration:  59%|█████▊    | 81/138 [00:12<00:09,  6.21it/s]\u001b[A\n",
            "Iteration:  59%|█████▉    | 82/138 [00:12<00:09,  6.22it/s]\u001b[A\n",
            "Iteration:  60%|██████    | 83/138 [00:13<00:08,  6.25it/s]\u001b[A\n",
            "Iteration:  61%|██████    | 84/138 [00:13<00:08,  6.29it/s]\u001b[A\n",
            "Iteration:  62%|██████▏   | 85/138 [00:13<00:08,  6.27it/s]\u001b[A\n",
            "Iteration:  62%|██████▏   | 86/138 [00:13<00:08,  6.25it/s]\u001b[A\n",
            "Iteration:  63%|██████▎   | 87/138 [00:13<00:08,  6.22it/s]\u001b[A\n",
            "Iteration:  64%|██████▍   | 88/138 [00:13<00:08,  6.22it/s]\u001b[A\n",
            "Iteration:  64%|██████▍   | 89/138 [00:14<00:07,  6.23it/s]\u001b[A\n",
            "Iteration:  65%|██████▌   | 90/138 [00:14<00:07,  6.19it/s]\u001b[A\n",
            "Iteration:  66%|██████▌   | 91/138 [00:14<00:07,  6.21it/s]\u001b[A\n",
            "Iteration:  67%|██████▋   | 92/138 [00:14<00:07,  6.25it/s]\u001b[A\n",
            "Iteration:  67%|██████▋   | 93/138 [00:14<00:07,  6.25it/s]\u001b[A\n",
            "Iteration:  68%|██████▊   | 94/138 [00:14<00:07,  6.27it/s]\u001b[A\n",
            "Iteration:  69%|██████▉   | 95/138 [00:15<00:06,  6.27it/s]\u001b[A\n",
            "Iteration:  70%|██████▉   | 96/138 [00:15<00:06,  6.27it/s]\u001b[A\n",
            "Iteration:  70%|███████   | 97/138 [00:15<00:06,  6.28it/s]\u001b[A\n",
            "Iteration:  71%|███████   | 98/138 [00:15<00:06,  6.31it/s]\u001b[A\n",
            "Iteration:  72%|███████▏  | 99/138 [00:15<00:06,  6.30it/s]\u001b[A\n",
            "Iteration:  72%|███████▏  | 100/138 [00:15<00:06,  6.28it/s]\u001b[A\n",
            "Iteration:  73%|███████▎  | 101/138 [00:16<00:05,  6.29it/s]\u001b[A\n",
            "Iteration:  74%|███████▍  | 102/138 [00:16<00:05,  6.28it/s]\u001b[A\n",
            "Iteration:  75%|███████▍  | 103/138 [00:16<00:05,  6.27it/s]\u001b[A\n",
            "Iteration:  75%|███████▌  | 104/138 [00:16<00:05,  6.26it/s]\u001b[A\n",
            "Iteration:  76%|███████▌  | 105/138 [00:16<00:05,  6.28it/s]\u001b[A\n",
            "Iteration:  77%|███████▋  | 106/138 [00:16<00:05,  6.29it/s]\u001b[A\n",
            "Iteration:  78%|███████▊  | 107/138 [00:16<00:04,  6.25it/s]\u001b[A\n",
            "Iteration:  78%|███████▊  | 108/138 [00:17<00:04,  6.24it/s]\u001b[A\n",
            "Iteration:  79%|███████▉  | 109/138 [00:17<00:04,  6.27it/s]\u001b[A\n",
            "Iteration:  80%|███████▉  | 110/138 [00:17<00:04,  6.24it/s]\u001b[A\n",
            "Iteration:  80%|████████  | 111/138 [00:17<00:04,  6.30it/s]\u001b[A\n",
            "Iteration:  81%|████████  | 112/138 [00:17<00:04,  6.27it/s]\u001b[A\n",
            "Iteration:  82%|████████▏ | 113/138 [00:17<00:03,  6.26it/s]\u001b[A\n",
            "Iteration:  83%|████████▎ | 114/138 [00:18<00:03,  6.28it/s]\u001b[A\n",
            "Iteration:  83%|████████▎ | 115/138 [00:18<00:04,  5.49it/s]\u001b[A\n",
            "Iteration:  84%|████████▍ | 116/138 [00:18<00:04,  4.70it/s]\u001b[A\n",
            "Iteration:  85%|████████▍ | 117/138 [00:18<00:04,  4.40it/s]\u001b[A\n",
            "Iteration:  86%|████████▌ | 118/138 [00:19<00:04,  4.67it/s]\u001b[A\n",
            "Iteration:  86%|████████▌ | 119/138 [00:19<00:03,  4.86it/s]\u001b[A\n",
            "Iteration:  87%|████████▋ | 120/138 [00:19<00:03,  5.21it/s]\u001b[A\n",
            "Iteration:  88%|████████▊ | 121/138 [00:19<00:03,  5.04it/s]\u001b[A\n",
            "Iteration:  88%|████████▊ | 122/138 [00:19<00:03,  4.51it/s]\u001b[A\n",
            "Iteration:  89%|████████▉ | 123/138 [00:20<00:03,  4.18it/s]\u001b[A\n",
            "Iteration:  90%|████████▉ | 124/138 [00:20<00:03,  4.19it/s]\u001b[A\n",
            "Iteration:  91%|█████████ | 125/138 [00:20<00:02,  4.39it/s]\u001b[A\n",
            "Iteration:  91%|█████████▏| 126/138 [00:20<00:02,  4.80it/s]\u001b[A\n",
            "Iteration:  92%|█████████▏| 127/138 [00:20<00:02,  4.86it/s]\u001b[A\n",
            "Iteration:  93%|█████████▎| 128/138 [00:21<00:02,  4.27it/s]\u001b[A\n",
            "Iteration:  93%|█████████▎| 129/138 [00:21<00:02,  3.78it/s]\u001b[A\n",
            "Iteration:  94%|█████████▍| 130/138 [00:21<00:02,  3.83it/s]\u001b[A\n",
            "Iteration:  95%|█████████▍| 131/138 [00:22<00:01,  4.33it/s]\u001b[A\n",
            "Iteration:  96%|█████████▌| 132/138 [00:22<00:01,  4.75it/s]\u001b[A\n",
            "Iteration:  96%|█████████▋| 133/138 [00:22<00:00,  5.10it/s]\u001b[A\n",
            "Iteration:  97%|█████████▋| 134/138 [00:22<00:00,  5.39it/s]\u001b[A\n",
            "Iteration:  98%|█████████▊| 135/138 [00:22<00:00,  5.55it/s]\u001b[A\n",
            "Iteration:  99%|█████████▊| 136/138 [00:22<00:00,  5.72it/s]\u001b[A\n",
            "Iteration:  99%|█████████▉| 137/138 [00:22<00:00,  5.88it/s]\u001b[A\n",
            "Iteration: 100%|██████████| 138/138 [00:23<00:00,  5.96it/s]\n",
            "Epoch:  60%|██████    | 3/5 [01:16<00:49, 24.55s/it]\n",
            "Iteration:   0%|          | 0/138 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1%|          | 1/138 [00:00<00:21,  6.39it/s]\u001b[A\n",
            "Iteration:   1%|▏         | 2/138 [00:00<00:21,  6.28it/s]\u001b[A\n",
            "Iteration:   2%|▏         | 3/138 [00:00<00:21,  6.31it/s]\u001b[A\n",
            "Iteration:   3%|▎         | 4/138 [00:00<00:21,  6.33it/s]\u001b[A\n",
            "Iteration:   4%|▎         | 5/138 [00:00<00:21,  6.28it/s]\u001b[A\n",
            "Iteration:   4%|▍         | 6/138 [00:00<00:21,  6.28it/s]\u001b[A\n",
            "Iteration:   5%|▌         | 7/138 [00:01<00:20,  6.26it/s]\u001b[A\n",
            "Iteration:   6%|▌         | 8/138 [00:01<00:20,  6.23it/s]\u001b[A\n",
            "Iteration:   7%|▋         | 9/138 [00:01<00:20,  6.24it/s]\u001b[A\n",
            "Iteration:   7%|▋         | 10/138 [00:01<00:20,  6.23it/s]\u001b[A\n",
            "Iteration:   8%|▊         | 11/138 [00:01<00:20,  6.25it/s]\u001b[A\n",
            "Iteration:   9%|▊         | 12/138 [00:01<00:20,  6.23it/s]\u001b[A\n",
            "Iteration:   9%|▉         | 13/138 [00:02<00:20,  6.23it/s]\u001b[A\n",
            "Iteration:  10%|█         | 14/138 [00:02<00:19,  6.22it/s]\u001b[A\n",
            "Iteration:  11%|█         | 15/138 [00:02<00:19,  6.18it/s]\u001b[A\n",
            "Iteration:  12%|█▏        | 16/138 [00:02<00:19,  6.23it/s]\u001b[A\n",
            "Iteration:  12%|█▏        | 17/138 [00:02<00:19,  6.22it/s]\u001b[A\n",
            "Iteration:  13%|█▎        | 18/138 [00:02<00:19,  6.19it/s]\u001b[A\n",
            "Iteration:  14%|█▍        | 19/138 [00:03<00:19,  6.20it/s]\u001b[A\n",
            "Iteration:  14%|█▍        | 20/138 [00:03<00:19,  6.18it/s]\u001b[A\n",
            "Iteration:  15%|█▌        | 21/138 [00:03<00:18,  6.16it/s]\u001b[A\n",
            "Iteration:  16%|█▌        | 22/138 [00:03<00:18,  6.16it/s]\u001b[A\n",
            "Iteration:  17%|█▋        | 23/138 [00:03<00:18,  6.14it/s]\u001b[A\n",
            "Iteration:  17%|█▋        | 24/138 [00:03<00:18,  6.18it/s]\u001b[A\n",
            "Iteration:  18%|█▊        | 25/138 [00:04<00:18,  6.19it/s]\u001b[A\n",
            "Iteration:  19%|█▉        | 26/138 [00:04<00:18,  6.17it/s]\u001b[A\n",
            "Iteration:  20%|█▉        | 27/138 [00:04<00:18,  6.14it/s]\u001b[A\n",
            "Iteration:  20%|██        | 28/138 [00:04<00:17,  6.17it/s]\u001b[A\n",
            "Iteration:  21%|██        | 29/138 [00:04<00:17,  6.16it/s]\u001b[A\n",
            "Iteration:  22%|██▏       | 30/138 [00:04<00:17,  6.17it/s]\u001b[A\n",
            "Iteration:  22%|██▏       | 31/138 [00:04<00:17,  6.18it/s]\u001b[A\n",
            "Iteration:  23%|██▎       | 32/138 [00:05<00:17,  6.16it/s]\u001b[A\n",
            "Iteration:  24%|██▍       | 33/138 [00:05<00:17,  6.14it/s]\u001b[A\n",
            "Iteration:  25%|██▍       | 34/138 [00:05<00:16,  6.13it/s]\u001b[A\n",
            "Iteration:  25%|██▌       | 35/138 [00:05<00:16,  6.17it/s]\u001b[A\n",
            "Iteration:  26%|██▌       | 36/138 [00:05<00:16,  6.17it/s]\u001b[A\n",
            "Iteration:  27%|██▋       | 37/138 [00:05<00:16,  6.16it/s]\u001b[A\n",
            "Iteration:  28%|██▊       | 38/138 [00:06<00:16,  6.17it/s]\u001b[A\n",
            "Iteration:  28%|██▊       | 39/138 [00:06<00:16,  6.16it/s]\u001b[A\n",
            "Iteration:  29%|██▉       | 40/138 [00:06<00:16,  6.12it/s]\u001b[A\n",
            "Iteration:  30%|██▉       | 41/138 [00:06<00:15,  6.12it/s]\u001b[A\n",
            "Iteration:  30%|███       | 42/138 [00:06<00:15,  6.14it/s]\u001b[A\n",
            "Iteration:  31%|███       | 43/138 [00:06<00:15,  6.14it/s]\u001b[A\n",
            "Iteration:  32%|███▏      | 44/138 [00:07<00:15,  6.14it/s]\u001b[A\n",
            "Iteration:  33%|███▎      | 45/138 [00:07<00:15,  6.15it/s]\u001b[A\n",
            "Iteration:  33%|███▎      | 46/138 [00:07<00:14,  6.15it/s]\u001b[A\n",
            "Iteration:  34%|███▍      | 47/138 [00:07<00:14,  6.12it/s]\u001b[A\n",
            "Iteration:  35%|███▍      | 48/138 [00:07<00:14,  6.13it/s]\u001b[A\n",
            "Iteration:  36%|███▌      | 49/138 [00:07<00:14,  6.13it/s]\u001b[A\n",
            "Iteration:  36%|███▌      | 50/138 [00:08<00:14,  6.14it/s]\u001b[A\n",
            "Iteration:  37%|███▋      | 51/138 [00:08<00:14,  6.13it/s]\u001b[A\n",
            "Iteration:  38%|███▊      | 52/138 [00:08<00:13,  6.16it/s]\u001b[A\n",
            "Iteration:  38%|███▊      | 53/138 [00:08<00:13,  6.15it/s]\u001b[A\n",
            "Iteration:  39%|███▉      | 54/138 [00:08<00:13,  6.15it/s]\u001b[A\n",
            "Iteration:  40%|███▉      | 55/138 [00:08<00:13,  6.16it/s]\u001b[A\n",
            "Iteration:  41%|████      | 56/138 [00:09<00:13,  6.16it/s]\u001b[A\n",
            "Iteration:  41%|████▏     | 57/138 [00:09<00:13,  6.16it/s]\u001b[A\n",
            "Iteration:  42%|████▏     | 58/138 [00:09<00:13,  6.14it/s]\u001b[A\n",
            "Iteration:  43%|████▎     | 59/138 [00:09<00:12,  6.13it/s]\u001b[A\n",
            "Iteration:  43%|████▎     | 60/138 [00:09<00:12,  6.18it/s]\u001b[A\n",
            "Iteration:  44%|████▍     | 61/138 [00:09<00:12,  6.16it/s]\u001b[A\n",
            "Iteration:  45%|████▍     | 62/138 [00:10<00:12,  6.14it/s]\u001b[A\n",
            "Iteration:  46%|████▌     | 63/138 [00:10<00:12,  6.15it/s]\u001b[A\n",
            "Iteration:  46%|████▋     | 64/138 [00:10<00:12,  6.15it/s]\u001b[A\n",
            "Iteration:  47%|████▋     | 65/138 [00:10<00:11,  6.17it/s]\u001b[A\n",
            "Iteration:  48%|████▊     | 66/138 [00:10<00:11,  6.17it/s]\u001b[A\n",
            "Iteration:  49%|████▊     | 67/138 [00:10<00:11,  6.17it/s]\u001b[A\n",
            "Iteration:  49%|████▉     | 68/138 [00:11<00:11,  6.18it/s]\u001b[A\n",
            "Iteration:  50%|█████     | 69/138 [00:11<00:11,  6.17it/s]\u001b[A\n",
            "Iteration:  51%|█████     | 70/138 [00:11<00:10,  6.18it/s]\u001b[A\n",
            "Iteration:  51%|█████▏    | 71/138 [00:11<00:10,  6.19it/s]\u001b[A\n",
            "Iteration:  52%|█████▏    | 72/138 [00:11<00:10,  6.17it/s]\u001b[A\n",
            "Iteration:  53%|█████▎    | 73/138 [00:11<00:10,  6.18it/s]\u001b[A\n",
            "Iteration:  54%|█████▎    | 74/138 [00:11<00:10,  6.17it/s]\u001b[A\n",
            "Iteration:  54%|█████▍    | 75/138 [00:12<00:10,  6.18it/s]\u001b[A\n",
            "Iteration:  55%|█████▌    | 76/138 [00:12<00:10,  6.14it/s]\u001b[A\n",
            "Iteration:  56%|█████▌    | 77/138 [00:12<00:09,  6.14it/s]\u001b[A\n",
            "Iteration:  57%|█████▋    | 78/138 [00:12<00:09,  6.13it/s]\u001b[A\n",
            "Iteration:  57%|█████▋    | 79/138 [00:12<00:09,  6.16it/s]\u001b[A\n",
            "Iteration:  58%|█████▊    | 80/138 [00:12<00:09,  6.15it/s]\u001b[A\n",
            "Iteration:  59%|█████▊    | 81/138 [00:13<00:09,  6.15it/s]\u001b[A\n",
            "Iteration:  59%|█████▉    | 82/138 [00:13<00:09,  6.14it/s]\u001b[A\n",
            "Iteration:  60%|██████    | 83/138 [00:13<00:08,  6.13it/s]\u001b[A\n",
            "Iteration:  61%|██████    | 84/138 [00:13<00:08,  6.16it/s]\u001b[A\n",
            "Iteration:  62%|██████▏   | 85/138 [00:13<00:08,  6.18it/s]\u001b[A\n",
            "Iteration:  62%|██████▏   | 86/138 [00:13<00:08,  6.17it/s]\u001b[A\n",
            "Iteration:  63%|██████▎   | 87/138 [00:14<00:08,  6.16it/s]\u001b[A\n",
            "Iteration:  64%|██████▍   | 88/138 [00:14<00:08,  6.16it/s]\u001b[A\n",
            "Iteration:  64%|██████▍   | 89/138 [00:14<00:07,  6.13it/s]\u001b[A\n",
            "Iteration:  65%|██████▌   | 90/138 [00:14<00:07,  6.12it/s]\u001b[A\n",
            "Iteration:  66%|██████▌   | 91/138 [00:14<00:07,  6.12it/s]\u001b[A\n",
            "Iteration:  67%|██████▋   | 92/138 [00:14<00:07,  6.16it/s]\u001b[A\n",
            "Iteration:  67%|██████▋   | 93/138 [00:15<00:07,  6.12it/s]\u001b[A\n",
            "Iteration:  68%|██████▊   | 94/138 [00:15<00:07,  6.12it/s]\u001b[A\n",
            "Iteration:  69%|██████▉   | 95/138 [00:15<00:07,  6.12it/s]\u001b[A\n",
            "Iteration:  70%|██████▉   | 96/138 [00:15<00:06,  6.13it/s]\u001b[A\n",
            "Iteration:  70%|███████   | 97/138 [00:15<00:06,  6.16it/s]\u001b[A\n",
            "Iteration:  71%|███████   | 98/138 [00:15<00:06,  6.20it/s]\u001b[A\n",
            "Iteration:  72%|███████▏  | 99/138 [00:16<00:06,  6.16it/s]\u001b[A\n",
            "Iteration:  72%|███████▏  | 100/138 [00:16<00:06,  6.16it/s]\u001b[A\n",
            "Iteration:  73%|███████▎  | 101/138 [00:16<00:05,  6.20it/s]\u001b[A\n",
            "Iteration:  74%|███████▍  | 102/138 [00:16<00:05,  6.14it/s]\u001b[A\n",
            "Iteration:  75%|███████▍  | 103/138 [00:16<00:05,  6.14it/s]\u001b[A\n",
            "Iteration:  75%|███████▌  | 104/138 [00:16<00:05,  6.17it/s]\u001b[A\n",
            "Iteration:  76%|███████▌  | 105/138 [00:17<00:05,  6.07it/s]\u001b[A\n",
            "Iteration:  77%|███████▋  | 106/138 [00:17<00:05,  6.06it/s]\u001b[A\n",
            "Iteration:  78%|███████▊  | 107/138 [00:17<00:05,  6.08it/s]\u001b[A\n",
            "Iteration:  78%|███████▊  | 108/138 [00:17<00:04,  6.10it/s]\u001b[A\n",
            "Iteration:  79%|███████▉  | 109/138 [00:17<00:04,  6.07it/s]\u001b[A\n",
            "Iteration:  80%|███████▉  | 110/138 [00:17<00:04,  6.06it/s]\u001b[A\n",
            "Iteration:  80%|████████  | 111/138 [00:18<00:04,  6.06it/s]\u001b[A\n",
            "Iteration:  81%|████████  | 112/138 [00:18<00:04,  6.07it/s]\u001b[A\n",
            "Iteration:  82%|████████▏ | 113/138 [00:18<00:04,  6.10it/s]\u001b[A\n",
            "Iteration:  83%|████████▎ | 114/138 [00:18<00:03,  6.11it/s]\u001b[A\n",
            "Iteration:  83%|████████▎ | 115/138 [00:18<00:03,  6.07it/s]\u001b[A\n",
            "Iteration:  84%|████████▍ | 116/138 [00:18<00:03,  6.08it/s]\u001b[A\n",
            "Iteration:  85%|████████▍ | 117/138 [00:19<00:03,  6.08it/s]\u001b[A\n",
            "Iteration:  86%|████████▌ | 118/138 [00:19<00:03,  6.08it/s]\u001b[A\n",
            "Iteration:  86%|████████▌ | 119/138 [00:19<00:03,  6.07it/s]\u001b[A\n",
            "Iteration:  87%|████████▋ | 120/138 [00:19<00:02,  6.14it/s]\u001b[A\n",
            "Iteration:  88%|████████▊ | 121/138 [00:19<00:02,  6.12it/s]\u001b[A\n",
            "Iteration:  88%|████████▊ | 122/138 [00:19<00:02,  6.10it/s]\u001b[A\n",
            "Iteration:  89%|████████▉ | 123/138 [00:19<00:02,  6.13it/s]\u001b[A\n",
            "Iteration:  90%|████████▉ | 124/138 [00:20<00:02,  6.10it/s]\u001b[A\n",
            "Iteration:  91%|█████████ | 125/138 [00:20<00:02,  6.09it/s]\u001b[A\n",
            "Iteration:  91%|█████████▏| 126/138 [00:20<00:01,  6.09it/s]\u001b[A\n",
            "Iteration:  92%|█████████▏| 127/138 [00:20<00:01,  6.05it/s]\u001b[A\n",
            "Iteration:  93%|█████████▎| 128/138 [00:20<00:01,  6.08it/s]\u001b[A\n",
            "Iteration:  93%|█████████▎| 129/138 [00:20<00:01,  6.07it/s]\u001b[A\n",
            "Iteration:  94%|█████████▍| 130/138 [00:21<00:01,  6.07it/s]\u001b[A\n",
            "Iteration:  95%|█████████▍| 131/138 [00:21<00:01,  6.09it/s]\u001b[A\n",
            "Iteration:  96%|█████████▌| 132/138 [00:21<00:00,  6.08it/s]\u001b[A\n",
            "Iteration:  96%|█████████▋| 133/138 [00:21<00:00,  6.11it/s]\u001b[A\n",
            "Iteration:  97%|█████████▋| 134/138 [00:21<00:00,  6.14it/s]\u001b[A\n",
            "Iteration:  98%|█████████▊| 135/138 [00:21<00:00,  6.16it/s]\u001b[A\n",
            "Iteration:  99%|█████████▊| 136/138 [00:22<00:00,  6.16it/s]\u001b[A\n",
            "Iteration:  99%|█████████▉| 137/138 [00:22<00:00,  6.12it/s]\u001b[A\n",
            "Iteration: 100%|██████████| 138/138 [00:22<00:00,  6.15it/s]\n",
            "Epoch:  80%|████████  | 4/5 [01:38<00:23, 23.73s/it]\n",
            "Iteration:   0%|          | 0/138 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1%|          | 1/138 [00:00<00:21,  6.25it/s]\u001b[A\n",
            "Iteration:   1%|▏         | 2/138 [00:00<00:22,  6.18it/s]\u001b[A\n",
            "Iteration:   2%|▏         | 3/138 [00:00<00:22,  6.09it/s]\u001b[A\n",
            "Iteration:   3%|▎         | 4/138 [00:00<00:21,  6.13it/s]\u001b[A\n",
            "Iteration:   4%|▎         | 5/138 [00:00<00:21,  6.09it/s]\u001b[A\n",
            "Iteration:   4%|▍         | 6/138 [00:00<00:21,  6.07it/s]\u001b[A\n",
            "Iteration:   5%|▌         | 7/138 [00:01<00:21,  6.10it/s]\u001b[A\n",
            "Iteration:   6%|▌         | 8/138 [00:01<00:21,  6.14it/s]\u001b[A\n",
            "Iteration:   7%|▋         | 9/138 [00:01<00:20,  6.16it/s]\u001b[A\n",
            "Iteration:   7%|▋         | 10/138 [00:01<00:20,  6.15it/s]\u001b[A\n",
            "Iteration:   8%|▊         | 11/138 [00:01<00:20,  6.11it/s]\u001b[A\n",
            "Iteration:   9%|▊         | 12/138 [00:01<00:20,  6.07it/s]\u001b[A\n",
            "Iteration:   9%|▉         | 13/138 [00:02<00:20,  6.10it/s]\u001b[A\n",
            "Iteration:  10%|█         | 14/138 [00:02<00:20,  6.15it/s]\u001b[A\n",
            "Iteration:  11%|█         | 15/138 [00:02<00:20,  6.11it/s]\u001b[A\n",
            "Iteration:  12%|█▏        | 16/138 [00:02<00:19,  6.17it/s]\u001b[A\n",
            "Iteration:  12%|█▏        | 17/138 [00:02<00:19,  6.16it/s]\u001b[A\n",
            "Iteration:  13%|█▎        | 18/138 [00:02<00:19,  6.13it/s]\u001b[A\n",
            "Iteration:  14%|█▍        | 19/138 [00:03<00:19,  6.06it/s]\u001b[A\n",
            "Iteration:  14%|█▍        | 20/138 [00:03<00:19,  6.07it/s]\u001b[A\n",
            "Iteration:  15%|█▌        | 21/138 [00:03<00:19,  6.06it/s]\u001b[A\n",
            "Iteration:  16%|█▌        | 22/138 [00:03<00:18,  6.17it/s]\u001b[A\n",
            "Iteration:  17%|█▋        | 23/138 [00:03<00:19,  6.01it/s]\u001b[A\n",
            "Iteration:  17%|█▋        | 24/138 [00:03<00:19,  5.99it/s]\u001b[A\n",
            "Iteration:  18%|█▊        | 25/138 [00:04<00:18,  5.99it/s]\u001b[A\n",
            "Iteration:  19%|█▉        | 26/138 [00:04<00:18,  5.96it/s]\u001b[A\n",
            "Iteration:  20%|█▉        | 27/138 [00:04<00:18,  6.02it/s]\u001b[A\n",
            "Iteration:  20%|██        | 28/138 [00:04<00:18,  6.08it/s]\u001b[A\n",
            "Iteration:  21%|██        | 29/138 [00:04<00:17,  6.08it/s]\u001b[A\n",
            "Iteration:  22%|██▏       | 30/138 [00:04<00:17,  6.09it/s]\u001b[A\n",
            "Iteration:  22%|██▏       | 31/138 [00:05<00:17,  6.06it/s]\u001b[A\n",
            "Iteration:  23%|██▎       | 32/138 [00:05<00:17,  6.10it/s]\u001b[A\n",
            "Iteration:  24%|██▍       | 33/138 [00:05<00:17,  6.06it/s]\u001b[A\n",
            "Iteration:  25%|██▍       | 34/138 [00:05<00:17,  6.02it/s]\u001b[A\n",
            "Iteration:  25%|██▌       | 35/138 [00:05<00:17,  6.04it/s]\u001b[A\n",
            "Iteration:  26%|██▌       | 36/138 [00:05<00:16,  6.03it/s]\u001b[A\n",
            "Iteration:  27%|██▋       | 37/138 [00:06<00:16,  6.02it/s]\u001b[A\n",
            "Iteration:  28%|██▊       | 38/138 [00:06<00:16,  5.99it/s]\u001b[A\n",
            "Iteration:  28%|██▊       | 39/138 [00:06<00:16,  6.03it/s]\u001b[A\n",
            "Iteration:  29%|██▉       | 40/138 [00:06<00:16,  5.98it/s]\u001b[A\n",
            "Iteration:  30%|██▉       | 41/138 [00:06<00:16,  6.03it/s]\u001b[A\n",
            "Iteration:  30%|███       | 42/138 [00:06<00:15,  6.08it/s]\u001b[A\n",
            "Iteration:  31%|███       | 43/138 [00:07<00:15,  6.07it/s]\u001b[A\n",
            "Iteration:  32%|███▏      | 44/138 [00:07<00:15,  6.09it/s]\u001b[A\n",
            "Iteration:  33%|███▎      | 45/138 [00:07<00:15,  6.01it/s]\u001b[A\n",
            "Iteration:  33%|███▎      | 46/138 [00:07<00:15,  6.00it/s]\u001b[A\n",
            "Iteration:  34%|███▍      | 47/138 [00:07<00:15,  5.96it/s]\u001b[A\n",
            "Iteration:  35%|███▍      | 48/138 [00:07<00:14,  6.04it/s]\u001b[A\n",
            "Iteration:  36%|███▌      | 49/138 [00:08<00:14,  6.05it/s]\u001b[A\n",
            "Iteration:  36%|███▌      | 50/138 [00:08<00:14,  6.07it/s]\u001b[A\n",
            "Iteration:  37%|███▋      | 51/138 [00:08<00:14,  5.99it/s]\u001b[A\n",
            "Iteration:  38%|███▊      | 52/138 [00:08<00:14,  6.00it/s]\u001b[A\n",
            "Iteration:  38%|███▊      | 53/138 [00:08<00:14,  6.00it/s]\u001b[A\n",
            "Iteration:  39%|███▉      | 54/138 [00:08<00:14,  5.96it/s]\u001b[A\n",
            "Iteration:  40%|███▉      | 55/138 [00:09<00:13,  6.01it/s]\u001b[A\n",
            "Iteration:  41%|████      | 56/138 [00:09<00:13,  5.99it/s]\u001b[A\n",
            "Iteration:  41%|████▏     | 57/138 [00:09<00:13,  6.00it/s]\u001b[A\n",
            "Iteration:  42%|████▏     | 58/138 [00:09<00:13,  6.03it/s]\u001b[A\n",
            "Iteration:  43%|████▎     | 59/138 [00:09<00:13,  6.07it/s]\u001b[A\n",
            "Iteration:  43%|████▎     | 60/138 [00:09<00:12,  6.08it/s]\u001b[A\n",
            "Iteration:  44%|████▍     | 61/138 [00:10<00:12,  6.11it/s]\u001b[A\n",
            "Iteration:  45%|████▍     | 62/138 [00:10<00:12,  6.13it/s]\u001b[A\n",
            "Iteration:  46%|████▌     | 63/138 [00:10<00:12,  6.13it/s]\u001b[A\n",
            "Iteration:  46%|████▋     | 64/138 [00:10<00:12,  6.12it/s]\u001b[A\n",
            "Iteration:  47%|████▋     | 65/138 [00:10<00:11,  6.14it/s]\u001b[A\n",
            "Iteration:  48%|████▊     | 66/138 [00:10<00:11,  6.09it/s]\u001b[A\n",
            "Iteration:  49%|████▊     | 67/138 [00:11<00:11,  6.02it/s]\u001b[A\n",
            "Iteration:  49%|████▉     | 68/138 [00:11<00:11,  6.03it/s]\u001b[A\n",
            "Iteration:  50%|█████     | 69/138 [00:11<00:11,  6.05it/s]\u001b[A\n",
            "Iteration:  51%|█████     | 70/138 [00:11<00:11,  6.05it/s]\u001b[A\n",
            "Iteration:  51%|█████▏    | 71/138 [00:11<00:11,  6.02it/s]\u001b[A\n",
            "Iteration:  52%|█████▏    | 72/138 [00:11<00:10,  6.02it/s]\u001b[A\n",
            "Iteration:  53%|█████▎    | 73/138 [00:12<00:10,  6.01it/s]\u001b[A\n",
            "Iteration:  54%|█████▎    | 74/138 [00:12<00:10,  6.02it/s]\u001b[A\n",
            "Iteration:  54%|█████▍    | 75/138 [00:12<00:10,  6.06it/s]\u001b[A\n",
            "Iteration:  55%|█████▌    | 76/138 [00:12<00:10,  6.07it/s]\u001b[A\n",
            "Iteration:  56%|█████▌    | 77/138 [00:12<00:09,  6.11it/s]\u001b[A\n",
            "Iteration:  57%|█████▋    | 78/138 [00:12<00:09,  6.12it/s]\u001b[A\n",
            "Iteration:  57%|█████▋    | 79/138 [00:13<00:09,  6.11it/s]\u001b[A\n",
            "Iteration:  58%|█████▊    | 80/138 [00:13<00:09,  6.07it/s]\u001b[A\n",
            "Iteration:  59%|█████▊    | 81/138 [00:13<00:09,  6.06it/s]\u001b[A\n",
            "Iteration:  59%|█████▉    | 82/138 [00:13<00:09,  6.01it/s]\u001b[A\n",
            "Iteration:  60%|██████    | 83/138 [00:13<00:09,  6.03it/s]\u001b[A\n",
            "Iteration:  61%|██████    | 84/138 [00:13<00:08,  6.07it/s]\u001b[A\n",
            "Iteration:  62%|██████▏   | 85/138 [00:14<00:08,  6.03it/s]\u001b[A\n",
            "Iteration:  62%|██████▏   | 86/138 [00:14<00:08,  6.08it/s]\u001b[A\n",
            "Iteration:  63%|██████▎   | 87/138 [00:14<00:08,  6.05it/s]\u001b[A\n",
            "Iteration:  64%|██████▍   | 88/138 [00:14<00:08,  6.02it/s]\u001b[A\n",
            "Iteration:  64%|██████▍   | 89/138 [00:14<00:08,  6.04it/s]\u001b[A\n",
            "Iteration:  65%|██████▌   | 90/138 [00:14<00:07,  6.05it/s]\u001b[A\n",
            "Iteration:  66%|██████▌   | 91/138 [00:15<00:07,  6.07it/s]\u001b[A\n",
            "Iteration:  67%|██████▋   | 92/138 [00:15<00:07,  6.10it/s]\u001b[A\n",
            "Iteration:  67%|██████▋   | 93/138 [00:15<00:07,  6.06it/s]\u001b[A\n",
            "Iteration:  68%|██████▊   | 94/138 [00:15<00:07,  6.05it/s]\u001b[A\n",
            "Iteration:  69%|██████▉   | 95/138 [00:15<00:07,  6.04it/s]\u001b[A\n",
            "Iteration:  70%|██████▉   | 96/138 [00:15<00:06,  6.05it/s]\u001b[A\n",
            "Iteration:  70%|███████   | 97/138 [00:16<00:06,  6.05it/s]\u001b[A\n",
            "Iteration:  71%|███████   | 98/138 [00:16<00:06,  6.04it/s]\u001b[A\n",
            "Iteration:  72%|███████▏  | 99/138 [00:16<00:06,  6.05it/s]\u001b[A\n",
            "Iteration:  72%|███████▏  | 100/138 [00:16<00:06,  6.10it/s]\u001b[A\n",
            "Iteration:  73%|███████▎  | 101/138 [00:16<00:06,  6.09it/s]\u001b[A\n",
            "Iteration:  74%|███████▍  | 102/138 [00:16<00:05,  6.06it/s]\u001b[A\n",
            "Iteration:  75%|███████▍  | 103/138 [00:16<00:05,  6.04it/s]\u001b[A\n",
            "Iteration:  75%|███████▌  | 104/138 [00:17<00:05,  6.03it/s]\u001b[A\n",
            "Iteration:  76%|███████▌  | 105/138 [00:17<00:05,  6.03it/s]\u001b[A\n",
            "Iteration:  77%|███████▋  | 106/138 [00:17<00:05,  6.05it/s]\u001b[A\n",
            "Iteration:  78%|███████▊  | 107/138 [00:17<00:05,  6.11it/s]\u001b[A\n",
            "Iteration:  78%|███████▊  | 108/138 [00:17<00:04,  6.06it/s]\u001b[A\n",
            "Iteration:  79%|███████▉  | 109/138 [00:17<00:04,  6.08it/s]\u001b[A\n",
            "Iteration:  80%|███████▉  | 110/138 [00:18<00:04,  6.16it/s]\u001b[A\n",
            "Iteration:  80%|████████  | 111/138 [00:18<00:04,  6.17it/s]\u001b[A\n",
            "Iteration:  81%|████████  | 112/138 [00:18<00:04,  6.17it/s]\u001b[A\n",
            "Iteration:  82%|████████▏ | 113/138 [00:18<00:04,  6.13it/s]\u001b[A\n",
            "Iteration:  83%|████████▎ | 114/138 [00:18<00:03,  6.15it/s]\u001b[A\n",
            "Iteration:  83%|████████▎ | 115/138 [00:18<00:03,  6.19it/s]\u001b[A\n",
            "Iteration:  84%|████████▍ | 116/138 [00:19<00:03,  6.16it/s]\u001b[A\n",
            "Iteration:  85%|████████▍ | 117/138 [00:19<00:03,  6.14it/s]\u001b[A\n",
            "Iteration:  86%|████████▌ | 118/138 [00:19<00:03,  6.13it/s]\u001b[A\n",
            "Iteration:  86%|████████▌ | 119/138 [00:19<00:03,  6.10it/s]\u001b[A\n",
            "Iteration:  87%|████████▋ | 120/138 [00:19<00:02,  6.08it/s]\u001b[A\n",
            "Iteration:  88%|████████▊ | 121/138 [00:19<00:02,  6.12it/s]\u001b[A\n",
            "Iteration:  88%|████████▊ | 122/138 [00:20<00:02,  6.18it/s]\u001b[A\n",
            "Iteration:  89%|████████▉ | 123/138 [00:20<00:02,  6.19it/s]\u001b[A\n",
            "Iteration:  90%|████████▉ | 124/138 [00:20<00:02,  6.15it/s]\u001b[A\n",
            "Iteration:  91%|█████████ | 125/138 [00:20<00:02,  6.16it/s]\u001b[A\n",
            "Iteration:  91%|█████████▏| 126/138 [00:20<00:01,  6.17it/s]\u001b[A\n",
            "Iteration:  92%|█████████▏| 127/138 [00:20<00:01,  6.19it/s]\u001b[A\n",
            "Iteration:  93%|█████████▎| 128/138 [00:21<00:01,  6.20it/s]\u001b[A\n",
            "Iteration:  93%|█████████▎| 129/138 [00:21<00:01,  6.12it/s]\u001b[A\n",
            "Iteration:  94%|█████████▍| 130/138 [00:21<00:01,  6.15it/s]\u001b[A\n",
            "Iteration:  95%|█████████▍| 131/138 [00:21<00:01,  6.17it/s]\u001b[A\n",
            "Iteration:  96%|█████████▌| 132/138 [00:21<00:00,  6.17it/s]\u001b[A\n",
            "Iteration:  96%|█████████▋| 133/138 [00:21<00:00,  6.16it/s]\u001b[A\n",
            "Iteration:  97%|█████████▋| 134/138 [00:22<00:00,  6.14it/s]\u001b[A\n",
            "Iteration:  98%|█████████▊| 135/138 [00:22<00:00,  6.16it/s]\u001b[A\n",
            "Iteration:  99%|█████████▊| 136/138 [00:22<00:00,  6.11it/s]\u001b[A\n",
            "Iteration:  99%|█████████▉| 137/138 [00:22<00:00,  6.12it/s]\u001b[A\n",
            "Iteration: 100%|██████████| 138/138 [00:22<00:00,  6.08it/s]\n",
            "Epoch: 100%|██████████| 5/5 [02:01<00:00, 24.31s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InClOPvSh6C-"
      },
      "source": [
        "# 7. Save / Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkYNtXZFsgF4"
      },
      "source": [
        "# # Save the trained model:\n",
        "# torch.save(model.state_dict(), '/content/gdrive/MyDrive/Colab Notebooks/R-BERT/data/das_model_train2')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrWDYmSYMMqf"
      },
      "source": [
        "# # Load the model, which was made on 8 GPUs (so the state_dict has a different format)\n",
        "# state_dict = torch.load('/content/gdrive/My Drive/Colab Notebooks/R-BERT/data/das_model_train2')\n",
        "\n",
        "# # Fix the format on the state_dict:\n",
        "\n",
        "# # create new OrderedDict that does not contain `module.`\n",
        "# from collections import OrderedDict\n",
        "# new_state_dict = OrderedDict()\n",
        "# for k, v in state_dict.items():\n",
        "#     name = k[7:] # remove `module.`\n",
        "#     new_state_dict[name] = v"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnSVUXX7vrQN"
      },
      "source": [
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() and not no_cuda else \"cpu\")\n",
        "\n",
        "\n",
        "# # Load the saved model from the state dict: \n",
        "# model = BertForSequenceClassification.from_pretrained(pretrained_model_name, config=bertconfig)\n",
        "# model.load_state_dict(new_state_dict)\n",
        "# model.to(device)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDJa8ZJBh_PR"
      },
      "source": [
        "# 8. Evaluate!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2rLtC2FVZpz"
      },
      "source": [
        "# Metrics for evaluation (accuracy, f1 score),  from the official script for SemEval task-8\n",
        "def acc_and_f1(preds, labels, average='macro'):\n",
        "    acc = simple_accuracy(preds, labels)\n",
        "    f1 = f1_score(y_true=labels, y_pred=preds, average=average)\n",
        "    return {\"acc\": acc,\n",
        "        \"f1\": f1,\n",
        "        \"acc_and_f1\": (acc + f1) / 2}\n",
        "    \n",
        "def compute_metrics(task_name, preds, labels):\n",
        "    assert len(preds) == len(labels)\n",
        "    return acc_and_f1(preds, labels)\n",
        "\n",
        "def simple_accuracy(preds, labels):\n",
        "    return (preds == labels).mean()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cAZ3OCmVZmh"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "def evaluate(model, tokenizer, prefix=\"\"):\n",
        "    '''\n",
        "    Reads the test set, makes predictions on it, saves the predictions\n",
        "    returns the predictions / truth and accuracy+f1 score.\n",
        "    '''\n",
        "    # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
        "\n",
        "    # What kind of task it was, for BERT:\n",
        "    eval_task = task_name\n",
        "\n",
        "    # Save the evaluation metrics into results:\n",
        "    results = {}\n",
        "\n",
        "    # Load the test set and convert to features and to tensors:\n",
        "    examples = get_test_examples('/content/gdrive/My Drive/Colab Notebooks/R-BERT/data')\n",
        "    features = convert_examples_to_features(\n",
        "        examples, labels, max_seq_len, tokenizer, \"classification\", use_entity_indicator)\n",
        "\n",
        "    all_input_ids = torch.tensor(\n",
        "            [f.input_ids for f in features], dtype=torch.long)\n",
        "    all_input_mask = torch.tensor(\n",
        "        [f.input_mask for f in features], dtype=torch.long)\n",
        "    all_segment_ids = torch.tensor(\n",
        "        [f.segment_ids for f in features], dtype=torch.long)\n",
        "    all_e1_mask = torch.tensor(\n",
        "        [f.e1_mask for f in features], dtype=torch.long)  # add e1 mask\n",
        "    all_e2_mask = torch.tensor(\n",
        "        [f.e2_mask for f in features], dtype=torch.long)  # add e2 mask\n",
        "\n",
        "    all_label_ids = torch.tensor(\n",
        "        [f.label_id for f in features], dtype=torch.long)\n",
        "\n",
        "    eval_dataset = TensorDataset(all_input_ids, all_input_mask,all_segment_ids, all_label_ids, all_e1_mask, all_e2_mask)\n",
        "\n",
        "    # Size of batch per GPU:\n",
        "    eval_batch_size = per_gpu_eval_batch_size * \\\n",
        "        max(1, n_gpu)\n",
        "\n",
        "    # Sample and load data:\n",
        "    eval_sampler = SequentialSampler(\n",
        "        eval_dataset) \n",
        "    eval_dataloader = DataLoader(\n",
        "        eval_dataset, sampler=eval_sampler, batch_size=eval_batch_size)\n",
        "\n",
        "\n",
        "  # Eval!\n",
        "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
        "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
        "    logger.info(\"  Batch size = %d\", eval_batch_size)\n",
        "    eval_loss = 0.0\n",
        "    nb_eval_steps = 0\n",
        "    preds = None\n",
        "    out_label_ids = None\n",
        "\n",
        "    # Loop through the test set, batch by batch:\n",
        "\n",
        "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "        model.eval()\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            inputs = {'input_ids':      batch[0],\n",
        "                      'attention_mask': batch[1],\n",
        "                      'token_type_ids': batch[2],\n",
        "                      'labels':      batch[3],\n",
        "                      'e1_mask': batch[4],\n",
        "                      'e2_mask': batch[5],\n",
        "                      }\n",
        "            outputs = model(**inputs)\n",
        "            tmp_eval_loss, logits = outputs[:2]\n",
        "\n",
        "            eval_loss += tmp_eval_loss.mean().item()\n",
        "        nb_eval_steps += 1\n",
        "      \n",
        "        #Calcualte the probalities for ROC/AUC\n",
        "        probabilities = F.softmax(logits, dim=-1)\n",
        "\n",
        "        # Extract the predictions from the model's output:\n",
        "        if preds is None:\n",
        "            preds = logits.detach().cpu().numpy()\n",
        "            out_label_ids = inputs['labels'].detach().cpu().numpy()\n",
        "        else:\n",
        "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
        "            out_label_ids = np.append(\n",
        "                out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n",
        "            \n",
        "    # Get the loss, prediction and results:\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    preds = np.argmax(preds, axis=1)\n",
        "\n",
        "\n",
        "    result = compute_metrics(eval_task, preds, out_label_ids)\n",
        "    results.update(result)\n",
        "\n",
        "    logger.info(\"***** Eval results {} *****\".format(prefix))\n",
        "    for key in sorted(result.keys()):\n",
        "        logger.info(\"  %s = %s\", key, str(result[key]))\n",
        "    \n",
        "    # Write results to file:\n",
        "    output_eval_file = \"/content/gdrive/My Drive/Colab Notebooks/R-BERT/eval/results2.txt\"\n",
        "    with open(output_eval_file, \"w\") as writer:\n",
        "        print(len(preds))\n",
        "        for key in range(len(preds)):\n",
        "            writer.write(\"%d\\t%s\\n\" %  (key, str(RELATION_LABELS[preds[key]-1])))\n",
        "                \n",
        "    return result, preds, out_label_ids, probabilities"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Your call to model.predict() is returning the logits for softmax. This is useful for training purposes.\n",
        "\n",
        "# # To get probabilties, you need to apply softmax on the logits.\n",
        "\n",
        "# import torch.nn.functional as F\n",
        "# logits = model.predict()\n",
        "# probabilities = F.softmax(logits, dim=-1)"
      ],
      "metadata": {
        "id": "FGsXIwxlJnd6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "from sklearn.metrics import matthews_corrcoef, f1_score\n",
        "\n",
        "RELATION_LABELS = ['left1-left2(e1,e2)',\n",
        "'right1-right2(e1,e2)',\n",
        "'l_pin1-l_pin2(e1,e2)',\n",
        "'r_pin1-r_pin2(e1,e2)']\n",
        "\n",
        "per_gpu_eval_batch_size=4\n",
        "\n",
        "result = evaluate(model, tokenizer)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QGS8ihqZvdg",
        "outputId": "b554ac39-6c4a-47c9-b78a-d5c9513c488b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 7/7 [00:00<00:00, 23.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'acc': 0.0, 'f1': 0.0, 'acc_and_f1': 0.0},\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0]),\n",
              " array([2, 1, 2, 4, 1, 3, 2, 1, 2, 1, 2, 4, 1, 3, 2, 1, 2, 1, 2, 1, 2, 1,\n",
              "        3, 2, 4, 1]),\n",
              " tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
              "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
              "        device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = result[1]\n",
        "y2 = result[2]"
      ],
      "metadata": {
        "id": "dQg7UYsb2jSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(result[3]])"
      ],
      "metadata": {
        "id": "FOk8WilH_tfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = [2, 2, 2, 4, 1, 3, 2, 1, 2, 2, 2, 4, 4, 3, 2, 1, 2, 1, 2, 1, 2, 1, 3, 2, 4, 1]\n",
        "y2 = [2, 1, 2, 4, 1, 3, 2, 1, 2, 1, 2, 4, 1, 3, 2, 1, 2, 1, 2, 1, 2, 1, 3, 2, 4, 1]\n",
        "'''({'acc': 0.8846153846153846,\n",
        "  'f1': 0.924812030075188,\n",
        "  'acc_and_f1': 0.9047137073452862},\n",
        " array([2, 2, 2, 4, 1, 3, 2, 1, 1, 1, 2, 4, 1, 3, 2, 1, 2, 1, 1, 1, 2, 1,\n",
        "        3, 2, 4, 1]),\n",
        " array([2, 1, 2, 4, 1, 3, 2, 1, 2, 1, 2, 4, 1, 3, 2, 1, 2, 1, 2, 1, 2, 1,\n",
        "        3, 2, 4, 1]),\n",
        " tensor([[2.2362e-04, 3.4219e-06, 2.1530e-02, 1.7892e-05, 9.7792e-01, 1.0060e-04,\n",
        "          3.2767e-05, 5.1960e-06, 1.5300e-05, 7.5195e-06, 1.4496e-05, 3.2002e-05,\n",
        "          2.7597e-06, 1.8904e-05, 2.2435e-05, 2.6208e-05, 1.7489e-05, 4.8732e-06],\n",
        "         [1.9342e-10, 1.0000e+00, 8.6637e-12, 1.9156e-09, 5.2488e-10, 1.8394e-10,\n",
        "          1.4103e-07, 3.7453e-10, 6.8952e-12, 9.2901e-12, 9.7561e-11, 1.8463e-10,\n",
        "          3.9704e-11, 2.1947e-11, 9.5502e-10, 1.9716e-10, 2.4306e-10, 2.9897e-10]],\n",
        "        device='cuda:0')) '''"
      ],
      "metadata": {
        "id": "DLmU7fhdM97N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "precision_recall_fscore_support(y2, y_pred, average='macro')"
      ],
      "metadata": {
        "id": "6f8irRT1SBPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "8Cxgz-XKNf8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cf_matrix = confusion_matrix(y2, y_pred)\n",
        "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
        "            fmt='.2%', cmap='Blues')"
      ],
      "metadata": {
        "id": "YPz_1VnCNf_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_roc_coordinates(y_real, y_proba):\n",
        "    '''\n",
        "    Calculates all the ROC Curve coordinates (tpr and fpr) by considering each point as a treshold for the predicion of the class.\n",
        "    \n",
        "    Args:\n",
        "        y_real: The list or series with the real classes.\n",
        "        y_proba: The array with the probabilities for each class, obtained by using the `.predict_proba()` method.\n",
        "        \n",
        "    Returns:\n",
        "        tpr_list: The list of TPRs representing each threshold.\n",
        "        fpr_list: The list of FPRs representing each threshold.\n",
        "    '''\n",
        "    tpr_list = [0]\n",
        "    fpr_list = [0]\n",
        "    for i in range(len(y_proba)):\n",
        "        threshold = y_proba[i]\n",
        "        y_pred = y_proba >= threshold\n",
        "        tpr, fpr = calculate_tpr_fpr(y_real, y_pred)\n",
        "        tpr_list.append(tpr)\n",
        "        fpr_list.append(fpr)\n",
        "    return tpr_list, fpr_list"
      ],
      "metadata": {
        "id": "OB3hYBY-5ml0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_tpr_fpr(y_real, y_pred):\n",
        "    '''\n",
        "    Calculates the True Positive Rate (tpr) and the True Negative Rate (fpr) based on real and predicted observations\n",
        "    \n",
        "    Args:\n",
        "        y_real: The list or series with the real classes\n",
        "        y_pred: The list or series with the predicted classes\n",
        "        \n",
        "    Returns:\n",
        "        tpr: The True Positive Rate of the classifier\n",
        "        fpr: The False Positive Rate of the classifier\n",
        "    '''\n",
        "    \n",
        "    # Calculates the confusion matrix and recover each element\n",
        "    cm = confusion_matrix(y_real, y_pred)\n",
        "    TN = cm[0, 0]\n",
        "    FP = cm[0, 1]\n",
        "    FN = cm[1, 0]\n",
        "    TP = cm[1, 1]\n",
        "    \n",
        "    # Calculates tpr and fpr\n",
        "    tpr =  TP/(TP + FN) # sensitivity - true positive rate\n",
        "    fpr = 1 - TN/(TN+FP) # 1-specificity - false positive rate\n",
        "    \n",
        "    return tpr, fpr"
      ],
      "metadata": {
        "id": "mmCqUyyT5ulb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_roc_curve(tpr, fpr, scatter = True, ax = None):\n",
        "    '''\n",
        "    Plots the ROC Curve by using the list of coordinates (tpr and fpr).\n",
        "    \n",
        "    Args:\n",
        "        tpr: The list of TPRs representing each coordinate.\n",
        "        fpr: The list of FPRs representing each coordinate.\n",
        "        scatter: When True, the points used on the calculation will be plotted with the line (default = True).\n",
        "    '''\n",
        "    if ax == None:\n",
        "        plt.figure(figsize = (5, 5))\n",
        "        ax = plt.axes()\n",
        "    \n",
        "    if scatter:\n",
        "        sns.scatterplot(x = fpr, y = tpr, ax = ax)\n",
        "    sns.lineplot(x = fpr, y = tpr, ax = ax)\n",
        "    sns.lineplot(x = [0, 1], y = [0, 1], color = 'green', ax = ax)\n",
        "    plt.xlim(-0.05, 1.05)\n",
        "    plt.ylim(-0.05, 1.05)\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")"
      ],
      "metadata": {
        "id": "iIEWjoSX50ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plots the Probability Distributions and the ROC Curves One vs Rest\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "plt.figure(figsize = (12, 8))\n",
        "bins = [i/20 for i in range(20)] + [1]\n",
        "classes = [1, 2, 3, 4]\n",
        "roc_auc_ovr = {}\n",
        "for i in range(len(classes)):\n",
        "    # Gets the class\n",
        "    c = classes[i]\n",
        "    \n",
        "    # Prepares an auxiliar dataframe to help with the plots\n",
        "    df_aux = pd.DataFrame()\n",
        "    df_aux['class'] = [1 if y == c else 0 for y in y_pred]\n",
        "    df_aux['prob'] = \n",
        "    # df_aux = df_aux.reset_index(drop = True)\n",
        "    \n",
        "    # Plots the probability distribution for the class and the rest\n",
        "    ax = plt.subplot(2, 3, i+1)\n",
        "    sns.histplot(x = \"prob\", data = df_aux, hue = 'class', color = 'b', ax = ax, bins = bins)\n",
        "    ax.set_title(c)\n",
        "    ax.legend([f\"Class: {c}\", \"Rest\"])\n",
        "    ax.set_xlabel(f\"P(x = {c})\")\n",
        "    \n",
        "    # Calculates the ROC Coordinates and plots the ROC Curves\n",
        "    ax_bottom = plt.subplot(2, 3, i+4)\n",
        "    tpr, fpr = get_all_roc_coordinates(df_aux['class'], df_aux['prob'])\n",
        "    plot_roc_curve(tpr, fpr, scatter = False, ax = ax_bottom)\n",
        "    ax_bottom.set_title(\"ROC Curve OvR\")\n",
        "    \n",
        "    # Calculates the ROC AUC OvR\n",
        "    roc_auc_ovr[c] = roc_auc_score(df_aux['class'], df_aux['prob'])\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "-6hHJW0S3TU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_aux"
      ],
      "metadata": {
        "id": "AILgChpF6uvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UNLKGChl3TW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oKsV7Xj63TaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# roc curve and auc\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from matplotlib import pyplot"
      ],
      "metadata": {
        "id": "_DRDpp02NujA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auc = roc_auc_score(y2, y_pred,  multi_class='ovr')"
      ],
      "metadata": {
        "id": "oBrlTtleNumM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q-Jht91RPmNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "from sklearn.metrics import matthews_corrcoef, f1_score\n",
        "\n",
        "RELATION_LABELS = ['left1-left2(e1,e2)',\n",
        "'right1-right2(e1,e2)',\n",
        "'l_pin1-l_pin2(e1,e2)',\n",
        "'r_pin1-r_pin2(e1,e2)',]\n",
        "\n",
        "per_gpu_eval_batch_size=4\n",
        "\n",
        "result = evaluate(model, tokenizer)\n",
        "result"
      ],
      "metadata": {
        "id": "-Bpg9fneYZ5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PYwpqShmNdWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmpSmesEuv2z"
      },
      "source": [
        "# Turns out that the model predicts over half of the classes correctly!\n",
        "\n",
        "\n",
        "Results of the evaluation:\n",
        "\n",
        "\n",
        "accuracy: \n",
        "\n",
        "f1-score (macro average): "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDHd-4Qy69En"
      },
      "source": [
        "Check what the predictions were, by running through the test file sentence by sentence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aA8kuVyjsEF8"
      },
      "source": [
        "# dict that relates the relation name and how it appears in the text:\n",
        "\n",
        "RELATIONZ = {\n",
        "'left1-left2(e1,e2)': '1 left1 left2 2',\n",
        "'right1-right2(e1,e2)': '1 right1 right2 2',\n",
        "'l_pin1-l_pin2(e1,e2)': '1 l_pin1 l_pin2 2',\n",
        "'r_pin1-r_pin2(e1,e2)': '1 r_pin1 rpin2 2'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6PU7S5tx8as"
      },
      "source": [
        "predictions = []\n",
        "with open('/content/gdrive/My Drive/Colab Notebooks/R-BERT/eval/results2.txt') as f:\n",
        "  for l in f.readlines():\n",
        "    predictions.append(l.split('\t')[1].strip())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o05A1uLvtsdf"
      },
      "source": [
        "# Check which predictions were correctly done by the model:\n",
        "\n",
        "with open('/content/gdrive/My Drive/Colab Notebooks/R-BERT/data/test.tsv') as f:\n",
        "  correct = set() \n",
        "  i = 0 \n",
        "  for l in f.readlines():\n",
        "    if RELATIONZ[predictions[i]] in l[-30:]:\n",
        "        print(predictions[i])\n",
        "        print(l[6:])\n",
        "        correct.add((l,predictions[i]))\n",
        "    i+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-qiJBgdv2Yt"
      },
      "source": [
        "It seems that the model only catches the causal relationships!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO5GXt-gx2jA"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "Counter([x[1] for x in correct])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXmfwsoxIlSm"
      },
      "source": [
        "What was the distribution of relationships in the training data?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6keHWR_J_yT"
      },
      "source": [
        "train_data = read_tsv('/content/gdrive/My Drive/Notebooks/R-BERT/data/train.tsv')\n",
        "\n",
        "Counter([(x[3],x[4]) for x in train_data])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9gD0Vtl8Ak-"
      },
      "source": [
        "What about the distribution of relationships in the test data?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVRH-rxS8GOP"
      },
      "source": [
        "test_data = read_tsv('/content/gdrive/My Drive/Notebooks/R-BERT/data/test.tsv')\n",
        "\n",
        "Counter([(x[3],x[4]) for x in test_data])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrwsWfTMN9XJ"
      },
      "source": [
        "The model only identifies 'treats' twice correctly, even though it is almost as abundant as 'causes'...\n",
        "\n",
        "What are 'treats' cases classified as?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj2OppQ5OKMq"
      },
      "source": [
        "treats = []\n",
        "with open('/content/gdrive/My Drive/Notebooks/R-BERT/data/test.tsv') as f:\n",
        "  \n",
        "  for i,l in enumerate(f.readlines()):\n",
        "    if 'treats' in l[-30:]:\n",
        "      # it is a \"treats\" relation \n",
        "        treats.append(predictions[i])\n",
        "        if predictions[i][:7] == 'treats2' or predictions[i][:7] == 'treats1':\n",
        "          # it is predicted to be a treats relation\n",
        "          print(l)\n",
        "          \n",
        "Counter(treats)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWG8lQ_O5Oed"
      },
      "source": [
        "# Confusion matrices, precision and recall for the 10 relations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEeUmwcFTGjI"
      },
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "\n",
        "# Grab the true predictions:\n",
        "\n",
        "truths = []\n",
        "with open('/content/gdrive/My Drive/Notebooks/R-BERT/data/test.tsv') as f:\n",
        "    for l in f.readlines():\n",
        "      found = False \n",
        "      for k,v in RELATIONZ.items():\n",
        "        if v in l:\n",
        "          truths.append(k) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj5KWCPoTuM7"
      },
      "source": [
        "confusion = multilabel_confusion_matrix(truths,predictions)\n",
        "\n",
        "for i,c in enumerate(confusion):\n",
        "  print(sorted(list(RELATIONZ.keys()))[i])\n",
        "  print(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxONacH2xH2B"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yjv1zIhkYP2y"
      },
      "source": [
        "The confusion matrices show that the accuracy of classification for each individual relation is pretty bad. \n",
        "\n",
        "What are the precision and recall for the 10 classes/relations?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmE5B1iRVMns"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "precision,recall,_,_ = precision_recall_fscore_support(truths,predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_F-xEUCvQPh"
      },
      "source": [
        "\n",
        "print('Precision    ', 'Recall')\n",
        "print()\n",
        "for i,p in enumerate(precision):\n",
        "  print(sorted(list(RELATIONZ.keys()))[i])\n",
        "  print('%.4f' % p, '      ', '%.4f' % recall[i])\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnF8KpEH7NyD"
      },
      "source": [
        "# References\n",
        "\n",
        "J.  Devlin,  M.-W.  Chang,  K.  Lee,  and  K.  Toutanova,  “Bert.”https://github.com/google-research/bert, 2018.  \n",
        "\n",
        "\n",
        "T. Wolf, L. Debut, V. Sanh, J. Chaumond, C. Delangue, A. Moi, P. Cistac,T. Rault, R. Louf, M. Funtowicz, and J. Brew, “Huggingface's transformers.”https://github.com/huggingface/transformers, 2019.\n",
        "\n",
        "\n",
        "H.   Wang,    “bert-relation-classification.”https://github.com/wang-h/bert-relation-classification, 2019."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"This 72 year old man attended the clinic for a routine follow up visit.   He underwent cataract surgery in his left eye and his vision has improved  Diagnosis  RE Cataract  LE Pseudophakia  RVA 6/36 ph 6/24 LVA 6/6  He has been listed for right phakoemulsification and iol and will be admitted on 8 Apr 2013.\"\n",
        "list_of_words = s.split()\n",
        "next_word = list_of_words[list_of_words.index('6/36') - 1]"
      ],
      "metadata": {
        "id": "KSEgrq5bmtgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next_word"
      ],
      "metadata": {
        "id": "t11zSLpYnHun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2OaM2itMnTPV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}